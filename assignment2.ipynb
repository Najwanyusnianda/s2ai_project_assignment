{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Candidate Pairs of Acronyms and Expansions (Assignment 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(\"dataacro.tar.gz\", \"r:gz\") as tar:\n",
    "    tar.extractall(\"dataacro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data length:  4000\n",
      "Training label length:  4000\n",
      "Testing data length:  1099\n",
      "Testing label length:  1099\n"
     ]
    }
   ],
   "source": [
    "def extract_feature(list_doc):\n",
    "    X=[]\n",
    "    y=[]\n",
    "    for i in range(len(list_doc)):\n",
    "        lines_feature=list_doc[i].split(\" \")[-8:len(list_doc[i])]\n",
    "        line_label=list_doc[i].split(\" \")[-9]\n",
    "        list_features=[float(line.strip().split(\":\")[1]) for line in lines_feature]\n",
    "        list_label=int(line_label) \n",
    "        X.append(list_features)\n",
    "        y.append(list_label)\n",
    "    \n",
    "    return X,y  \n",
    "\n",
    "with open(\"dataacro/trainingset.txt\", \"r\") as file:\n",
    "    training_lines = file.readlines()\n",
    "\n",
    "with open(\"dataacro/testingset.txt\", \"r\") as file:\n",
    "    testing_lines = file.readlines()\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "X_train,y_train=extract_feature(training_lines)\n",
    "X_test,y_test=extract_feature(testing_lines)   \n",
    "\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)\n",
    "#check data length\n",
    "print(\"Training data length: \", len(X_train))\n",
    "print(\"Training label length: \", len(y_train))\n",
    "print(\"Testing data length: \", len(X_test))\n",
    "print(\"Testing label length: \", len(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_model_result(y_true,y_pred):\n",
    "    cm=confusion_matrix(y_true,y_pred)\n",
    "    pre=precision_score(y_true,y_pred)\n",
    "    rec=recall_score(y_true,y_pred)\n",
    "    f1=f1_score(y_true,y_pred)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"Confusion Matrix\": [cm.tolist()],  # Convert to list to avoid issues\n",
    "        \"Precision\": [pre],\n",
    "        \"Recall\": [rec],\n",
    "        \"F1-Score\": [f1]\n",
    "    })\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.X SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(random_state=0)\n",
    "\n",
    "x = [1.0,10.0,100.0,500.0,1000.0]\n",
    "y = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "z = [2,3,4]    \n",
    "parameters=[{'C': x,'kernel': ['linear']},\n",
    "            {'C': x,'kernel': ['rbf'],'gamma': y} ,\n",
    "            {'C': x,'kernel': ['poly'],'gamma': y,'degree': z}\n",
    "           ]\n",
    "grid=GridSearchCV(estimator = svm,\n",
    "                        param_grid = parameters,\n",
    "                        scoring='accuracy',\n",
    "                        cv=10,\n",
    "                        n_jobs=-1)\n",
    "grid=grid.fit(X_train,y_train)\n",
    "\n",
    "print(f\"The best parameters are {grid.best_params_} with\" +\n",
    "          f\"a score of {grid.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.x KNN Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'n_neighbors': np.int64(9)} witha score of 0.92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[497, 3], [305, 294]]</td>\n",
       "      <td>0.989899</td>\n",
       "      <td>0.490818</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Confusion Matrix  Precision    Recall  F1-Score\n",
       "0  [[497, 3], [305, 294]]   0.989899  0.490818   0.65625"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build model\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {\"n_neighbors\": np.arange(2, 10)}\n",
    "grid = GridSearchCV(knn, param_grid=param_grid)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best parameters are {grid.best_params_} with\" +\n",
    "          f\"a score of {grid.best_score_:.2f}\")\n",
    "\n",
    "knn = grid.best_estimator_\n",
    "\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.99      0.76       500\n",
      "           1       0.99      0.49      0.66       599\n",
      "\n",
      "    accuracy                           0.72      1099\n",
      "   macro avg       0.80      0.74      0.71      1099\n",
      "weighted avg       0.82      0.72      0.71      1099\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = knn.predict(X_test)\n",
    "input_model_result(y_test,yhat)\n",
    "print(classification_report(y_test,yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
