{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: dataset/stagging/sampleset\\Amy_Davidson\n",
      "Deleted: dataset/stagging/testingset\\Amy_Davidson\n",
      "Deleted: dataset/stagging/validationset\\Amy_Davidson\n",
      "Deleted: dataset/stagging/sampleset\\Andrea_Anders\n",
      "Deleted: dataset/stagging/testingset\\Andrea_Anders\n",
      "Deleted: dataset/stagging/validationset\\Andrea_Anders\n",
      "Deleted: dataset/stagging/sampleset\\Angell_Conwell\n",
      "Deleted: dataset/stagging/testingset\\Angell_Conwell\n",
      "Deleted: dataset/stagging/validationset\\Angell_Conwell\n",
      "Deleted: dataset/stagging/sampleset\\Annie_Ilonzeh\n",
      "Deleted: dataset/stagging/testingset\\Annie_Ilonzeh\n",
      "Deleted: dataset/stagging/validationset\\Annie_Ilonzeh\n",
      "Deleted: dataset/stagging/sampleset\\Barbara_Carrera\n",
      "Deleted: dataset/stagging/testingset\\Barbara_Carrera\n",
      "Deleted: dataset/stagging/validationset\\Barbara_Carrera\n",
      "Deleted: dataset/stagging/sampleset\\Billy_Boyd\n",
      "Deleted: dataset/stagging/testingset\\Billy_Boyd\n",
      "Deleted: dataset/stagging/validationset\\Billy_Boyd\n",
      "Deleted: dataset/stagging/sampleset\\Christopher_Lloyd\n",
      "Deleted: dataset/stagging/testingset\\Christopher_Lloyd\n",
      "Deleted: dataset/stagging/validationset\\Christopher_Lloyd\n",
      "Deleted: dataset/stagging/sampleset\\Chris_Kattan\n",
      "Deleted: dataset/stagging/testingset\\Chris_Kattan\n",
      "Deleted: dataset/stagging/validationset\\Chris_Kattan\n",
      "Deleted: dataset/stagging/sampleset\\Chris_Klein\n",
      "Deleted: dataset/stagging/testingset\\Chris_Klein\n",
      "Deleted: dataset/stagging/validationset\\Chris_Klein\n",
      "Deleted: dataset/stagging/sampleset\\Delta_Burke\n",
      "Deleted: dataset/stagging/testingset\\Delta_Burke\n",
      "Deleted: dataset/stagging/validationset\\Delta_Burke\n",
      "Deleted: dataset/stagging/sampleset\\Erin_Cummings\n",
      "Deleted: dataset/stagging/testingset\\Erin_Cummings\n",
      "Deleted: dataset/stagging/validationset\\Erin_Cummings\n",
      "Deleted: dataset/stagging/sampleset\\Jackee_Harry\n",
      "Deleted: dataset/stagging/testingset\\Jackee_Harry\n",
      "Deleted: dataset/stagging/validationset\\Jackee_Harry\n",
      "Deleted: dataset/stagging/sampleset\\Jaden_Smith\n",
      "Deleted: dataset/stagging/testingset\\Jaden_Smith\n",
      "Deleted: dataset/stagging/validationset\\Jaden_Smith\n",
      "Deleted: dataset/stagging/sampleset\\James_Brolin\n",
      "Deleted: dataset/stagging/testingset\\James_Brolin\n",
      "Deleted: dataset/stagging/validationset\\James_Brolin\n",
      "Deleted: dataset/stagging/sampleset\\James_Remar\n",
      "Deleted: dataset/stagging/testingset\\James_Remar\n",
      "Deleted: dataset/stagging/validationset\\James_Remar\n",
      "Deleted: dataset/stagging/sampleset\\Jason_Statham\n",
      "Deleted: dataset/stagging/testingset\\Jason_Statham\n",
      "Deleted: dataset/stagging/validationset\\Jason_Statham\n",
      "Deleted: dataset/stagging/sampleset\\Jennifer_Gareis\n",
      "Deleted: dataset/stagging/testingset\\Jennifer_Gareis\n",
      "Deleted: dataset/stagging/validationset\\Jennifer_Gareis\n",
      "Deleted: dataset/stagging/sampleset\\Jessica_Leccia\n",
      "Deleted: dataset/stagging/testingset\\Jessica_Leccia\n",
      "Deleted: dataset/stagging/validationset\\Jessica_Leccia\n",
      "Deleted: dataset/stagging/sampleset\\Jill_Hennessy\n",
      "Deleted: dataset/stagging/testingset\\Jill_Hennessy\n",
      "Deleted: dataset/stagging/validationset\\Jill_Hennessy\n",
      "Deleted: dataset/stagging/sampleset\\Jim_Beaver\n",
      "Deleted: dataset/stagging/testingset\\Jim_Beaver\n",
      "Deleted: dataset/stagging/validationset\\Jim_Beaver\n",
      "Deleted: dataset/stagging/sampleset\\Josie_Bissett\n",
      "Deleted: dataset/stagging/testingset\\Josie_Bissett\n",
      "Deleted: dataset/stagging/validationset\\Josie_Bissett\n",
      "Deleted: dataset/stagging/sampleset\\Judith_Light\n",
      "Deleted: dataset/stagging/testingset\\Judith_Light\n",
      "Deleted: dataset/stagging/validationset\\Judith_Light\n",
      "Deleted: dataset/stagging/sampleset\\Julie_Marie_Berman\n",
      "Deleted: dataset/stagging/testingset\\Julie_Marie_Berman\n",
      "Deleted: dataset/stagging/validationset\\Julie_Marie_Berman\n",
      "Deleted: dataset/stagging/sampleset\\Kate_Linder\n",
      "Deleted: dataset/stagging/testingset\\Kate_Linder\n",
      "Deleted: dataset/stagging/validationset\\Kate_Linder\n",
      "Deleted: dataset/stagging/sampleset\\Kimberly_Matula\n",
      "Deleted: dataset/stagging/testingset\\Kimberly_Matula\n",
      "Deleted: dataset/stagging/validationset\\Kimberly_Matula\n",
      "Deleted: dataset/stagging/sampleset\\Lauralee_Bell\n",
      "Deleted: dataset/stagging/testingset\\Lauralee_Bell\n",
      "Deleted: dataset/stagging/validationset\\Lauralee_Bell\n",
      "Deleted: dataset/stagging/sampleset\\Laura_Innes\n",
      "Deleted: dataset/stagging/testingset\\Laura_Innes\n",
      "Deleted: dataset/stagging/validationset\\Laura_Innes\n",
      "Deleted: dataset/stagging/sampleset\\Lexi_Ainsworth\n",
      "Deleted: dataset/stagging/testingset\\Lexi_Ainsworth\n",
      "Deleted: dataset/stagging/validationset\\Lexi_Ainsworth\n",
      "Deleted: dataset/stagging/sampleset\\Linda_Gray\n",
      "Deleted: dataset/stagging/testingset\\Linda_Gray\n",
      "Deleted: dataset/stagging/validationset\\Linda_Gray\n",
      "Deleted: dataset/stagging/sampleset\\Lisa_LoCicero\n",
      "Deleted: dataset/stagging/testingset\\Lisa_LoCicero\n",
      "Deleted: dataset/stagging/validationset\\Lisa_LoCicero\n",
      "Deleted: dataset/stagging/sampleset\\Melissa_Benoist\n",
      "Deleted: dataset/stagging/testingset\\Melissa_Benoist\n",
      "Deleted: dataset/stagging/validationset\\Melissa_Benoist\n",
      "Deleted: dataset/stagging/sampleset\\Melissa_Gilbert\n",
      "Deleted: dataset/stagging/testingset\\Melissa_Gilbert\n",
      "Deleted: dataset/stagging/validationset\\Melissa_Gilbert\n",
      "Deleted: dataset/stagging/sampleset\\Natalie_Martinez\n",
      "Deleted: dataset/stagging/testingset\\Natalie_Martinez\n",
      "Deleted: dataset/stagging/validationset\\Natalie_Martinez\n",
      "Deleted: dataset/stagging/sampleset\\Neal_McDonough\n",
      "Deleted: dataset/stagging/testingset\\Neal_McDonough\n",
      "Deleted: dataset/stagging/validationset\\Neal_McDonough\n",
      "Deleted: dataset/stagging/sampleset\\Rupert_Friend\n",
      "Deleted: dataset/stagging/testingset\\Rupert_Friend\n",
      "Deleted: dataset/stagging/validationset\\Rupert_Friend\n",
      "Deleted: dataset/stagging/sampleset\\Samuel_L._Jackson\n",
      "Deleted: dataset/stagging/testingset\\Samuel_L._Jackson\n",
      "Deleted: dataset/stagging/validationset\\Samuel_L._Jackson\n",
      "Deleted: dataset/stagging/sampleset\\Scott_Patterson\n",
      "Deleted: dataset/stagging/testingset\\Scott_Patterson\n",
      "Deleted: dataset/stagging/validationset\\Scott_Patterson\n",
      "Deleted: dataset/stagging/sampleset\\Shelley_Hack\n",
      "Deleted: dataset/stagging/testingset\\Shelley_Hack\n",
      "Deleted: dataset/stagging/validationset\\Shelley_Hack\n",
      "Deleted: dataset/stagging/sampleset\\Tatyana_M._Ali\n",
      "Deleted: dataset/stagging/testingset\\Tatyana_M._Ali\n",
      "Deleted: dataset/stagging/validationset\\Tatyana_M._Ali\n",
      "Deleted: dataset/stagging/sampleset\\Tempestt_Bledsoe\n",
      "Deleted: dataset/stagging/testingset\\Tempestt_Bledsoe\n",
      "Deleted: dataset/stagging/validationset\\Tempestt_Bledsoe\n",
      "Deleted: dataset/stagging/sampleset\\Tina_Louise\n",
      "Deleted: dataset/stagging/testingset\\Tina_Louise\n",
      "Deleted: dataset/stagging/validationset\\Tina_Louise\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Subfolder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "File Count_Sampleset",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "File Count_Testingset",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "File Count_Validationset",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "44825f4d-c884-4876-8ba3-9484b49f511e",
       "rows": [
        [
         "0",
         "Alan_Alda",
         "20",
         "5",
         "5"
        ],
        [
         "1",
         "Alan_Arkin",
         "20",
         "5",
         "5"
        ],
        [
         "2",
         "Alec_Baldwin",
         "20",
         "5",
         "5"
        ],
        [
         "3",
         "Alfred_Molina",
         "20",
         "5",
         "5"
        ],
        [
         "4",
         "Alyssa_Milano",
         "20",
         "5",
         "5"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subfolder</th>\n",
       "      <th>File Count_Sampleset</th>\n",
       "      <th>File Count_Testingset</th>\n",
       "      <th>File Count_Validationset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan_Alda</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan_Arkin</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alec_Baldwin</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfred_Molina</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alyssa_Milano</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subfolder  File Count_Sampleset  File Count_Testingset  \\\n",
       "0      Alan_Alda                    20                      5   \n",
       "1     Alan_Arkin                    20                      5   \n",
       "2   Alec_Baldwin                    20                      5   \n",
       "3  Alfred_Molina                    20                      5   \n",
       "4  Alyssa_Milano                    20                      5   \n",
       "\n",
       "   File Count_Validationset  \n",
       "0                         5  \n",
       "1                         5  \n",
       "2                         5  \n",
       "3                         5  \n",
       "4                         5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "def list_subfolders_and_count_files(root_directory):\n",
    "    \"\"\"Lists subfolders and counts the number of files in each subfolder.\"\"\"\n",
    "    subfolder_file_counts = {}\n",
    "    for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "        if dirpath == root_directory:\n",
    "            for dirname in dirnames:\n",
    "                subfolder_path = os.path.join(dirpath, dirname)\n",
    "                file_count = len([f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))])\n",
    "                subfolder_file_counts[dirname] = file_count\n",
    "    return subfolder_file_counts\n",
    "\n",
    "# Define dataset paths\n",
    "sampleset_path = \"dataset/stagging/sampleset\"\n",
    "testingset_path = \"dataset/stagging/testingset\"\n",
    "validationset_path = \"dataset/stagging/validationset\"\n",
    "\n",
    "# Count files in each set\n",
    "df_Sampleset = pd.DataFrame(list(list_subfolders_and_count_files(sampleset_path).items()), columns=['Subfolder', 'File Count_Sampleset'])\n",
    "df_Testingset = pd.DataFrame(list(list_subfolders_and_count_files(testingset_path).items()), columns=['Subfolder', 'File Count_Testingset'])\n",
    "df_Validationset = pd.DataFrame(list(list_subfolders_and_count_files(validationset_path).items()), columns=['Subfolder', 'File Count_Validationset'])\n",
    "\n",
    "# Merge DataFrames\n",
    "df_combined = df_Sampleset.merge(df_Testingset, on='Subfolder', suffixes=('_Sampleset', '_Testingset'))\n",
    "df_combined = df_combined.merge(df_Validationset, on='Subfolder')\n",
    "df_combined.rename(columns={'File Count': 'File Count_Validationset'}, inplace=True)\n",
    "\n",
    "# Delete subfolders where File Count_Testingset < 5\n",
    "for subfolder in df_combined[df_combined['File Count_Testingset'] < 5]['Subfolder']:\n",
    "    for dataset_path in [sampleset_path, testingset_path, validationset_path]:\n",
    "        subfolder_path = os.path.join(dataset_path, subfolder)\n",
    "        if os.path.exists(subfolder_path):\n",
    "            shutil.rmtree(subfolder_path)  # Deletes folder and all its contents\n",
    "            print(f\"Deleted: {subfolder_path}\")\n",
    "\n",
    "# Display the updated dataframe\n",
    "df_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Subfolder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "File Count_Sampleset",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "File Count_Testingset",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "File Count_Validationset",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f98a4db0-9204-43f1-af8d-868caff552d0",
       "rows": [
        [
         "0",
         "Alan_Alda",
         "20",
         "5",
         "5"
        ],
        [
         "1",
         "Alan_Arkin",
         "20",
         "5",
         "5"
        ],
        [
         "2",
         "Alec_Baldwin",
         "20",
         "5",
         "5"
        ],
        [
         "3",
         "Alfred_Molina",
         "20",
         "5",
         "5"
        ],
        [
         "4",
         "Alyssa_Milano",
         "20",
         "5",
         "5"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subfolder</th>\n",
       "      <th>File Count_Sampleset</th>\n",
       "      <th>File Count_Testingset</th>\n",
       "      <th>File Count_Validationset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan_Alda</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan_Arkin</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alec_Baldwin</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfred_Molina</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alyssa_Milano</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subfolder  File Count_Sampleset  File Count_Testingset  \\\n",
       "0      Alan_Alda                    20                      5   \n",
       "1     Alan_Arkin                    20                      5   \n",
       "2   Alec_Baldwin                    20                      5   \n",
       "3  Alfred_Molina                    20                      5   \n",
       "4  Alyssa_Milano                    20                      5   \n",
       "\n",
       "   File Count_Validationset  \n",
       "0                         5  \n",
       "1                         5  \n",
       "2                         5  \n",
       "3                         5  \n",
       "4                         5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def list_subfolders_and_count_files(root_directory):\n",
    "    # Dictionary to store subfolder names and their file counts\n",
    "    subfolder_file_counts = {}\n",
    "\n",
    "    # Walk through the root directory\n",
    "    for dirpath, dirnames, filenames in os.walk(root_directory):\n",
    "        # We are only interested in immediate subfolders of the root directory\n",
    "        if dirpath == root_directory:\n",
    "            for dirname in dirnames:\n",
    "                subfolder_path = os.path.join(dirpath, dirname)\n",
    "                # Count the number of files in the subfolder\n",
    "                file_count = len([f for f in os.listdir(subfolder_path) if os.path.isfile(os.path.join(subfolder_path, f))])\n",
    "                subfolder_file_counts[dirname] = file_count\n",
    "\n",
    "    return subfolder_file_counts\n",
    "\n",
    "\n",
    "\n",
    "def save_subfolder_counts_to_dataframe(subfolder_counts, output_file):\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame(list(subfolder_counts.items()), columns=['Subfolder', 'File Count'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "sampleset_path=\"dataset/stagging/sampleset\"\n",
    "subfolder_counts = list_subfolders_and_count_files(sampleset_path)\n",
    "df_Sampleset = save_subfolder_counts_to_dataframe(subfolder_counts, \"subfolder_counts.csv\")\n",
    "\n",
    "testingset_path=\"dataset/stagging/testingset\"\n",
    "subfolder_counts = list_subfolders_and_count_files(testingset_path)\n",
    "df_Testingset = save_subfolder_counts_to_dataframe(subfolder_counts, \"subfolder_counts.csv\")\n",
    "\n",
    "validationset_path=\"dataset/stagging/validationset\"\n",
    "subfolder_counts = list_subfolders_and_count_files(validationset_path)\n",
    "df_Validationset = save_subfolder_counts_to_dataframe(subfolder_counts, \"subfolder_counts.csv\")\n",
    "\n",
    "# Merge the dataframes on the \"Subfolder\" column\n",
    "df_combined = df_Sampleset.merge(df_Testingset, on='Subfolder', suffixes=('_Sampleset', '_Testingset'))\n",
    "df_combined = df_combined.merge(df_Validationset, on='Subfolder')\n",
    "df_combined.rename(columns={'File Count': 'File Count_Validationset'}, inplace=True)\n",
    "\n",
    "# Display the combined dataframe\n",
    "df_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Subfolder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "File Count_Sampleset",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "File Count_Testingset",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "File Count_Validationset",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3667bf7b-ca27-42f2-89aa-e86409213fce",
       "rows": [
        [
         "0",
         "Alan_Alda",
         "20",
         "5",
         "5"
        ],
        [
         "1",
         "Alan_Arkin",
         "20",
         "5",
         "5"
        ],
        [
         "2",
         "Alec_Baldwin",
         "20",
         "5",
         "5"
        ],
        [
         "3",
         "Alfred_Molina",
         "20",
         "5",
         "5"
        ],
        [
         "4",
         "Alyssa_Milano",
         "20",
         "5",
         "5"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subfolder</th>\n",
       "      <th>File Count_Sampleset</th>\n",
       "      <th>File Count_Testingset</th>\n",
       "      <th>File Count_Validationset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan_Alda</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan_Arkin</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alec_Baldwin</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alfred_Molina</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alyssa_Milano</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Subfolder  File Count_Sampleset  File Count_Testingset  \\\n",
       "0      Alan_Alda                    20                      5   \n",
       "1     Alan_Arkin                    20                      5   \n",
       "2   Alec_Baldwin                    20                      5   \n",
       "3  Alfred_Molina                    20                      5   \n",
       "4  Alyssa_Milano                    20                      5   \n",
       "\n",
       "   File Count_Validationset  \n",
       "0                         5  \n",
       "1                         5  \n",
       "2                         5  \n",
       "3                         5  \n",
       "4                         5  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df_combined[\n",
    "    (df_combined['File Count_Sampleset'] == 20) &\n",
    "    (df_combined['File Count_Testingset'] == 0) &\n",
    "    (df_combined['File Count_Validationset'] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alan Arkin', 'Alan Rickman', 'Alyssa Milano', 'Andy Richter',\n",
       "       'Ashley Benson', 'Ashley Jones', 'Audrey Landers', 'Ben Kingsley',\n",
       "       'Billy Boyd', 'Billy Zane', 'Bobbie Eakes', 'Brad Pitt',\n",
       "       'Burt Reynolds', 'Carey Lowell', 'Caroline Dhavernas',\n",
       "       'Cary Elwes', 'Channing Tatum', 'Cheryl Hines', 'Cheryl Ladd',\n",
       "       'Chris Evans', 'Chris Rock', 'Christa Miller', 'Chyler Leigh',\n",
       "       'Courteney Cox', 'Crystal Chappell', 'Danica McKellar',\n",
       "       'David Cross', 'David Schwimmer', 'Dermot Mulroney',\n",
       "       'Desmond Harrington', 'Diego Luna', 'Dina Meyer', 'Dustin Hoffman',\n",
       "       'Edie Falco', 'Elijah Wood', 'Elizabeth Berkley',\n",
       "       'Elizabeth Hendrickson', 'Farah Fath', 'Frances Fisher',\n",
       "       'Gates McFadden', 'Geoffrey Rush', 'George Clooney',\n",
       "       'Harrison Ford', 'Hayden Christensen', 'Heather Locklear',\n",
       "       'Ioan Gruffudd', 'Jaden Smith', 'Jake Gyllenhaal', 'Jake Weber',\n",
       "       'James Frain', 'James Franco', 'James McAvoy', 'January Jones',\n",
       "       'Jason Lee', 'Jason Sudeikis', 'Jean Reno', 'Jeremy Sisto',\n",
       "       'Jerry Seinfeld', 'Jessica Capshaw', 'Jet Li', 'Joan Collins',\n",
       "       'John Cusack', 'Jon Voight', 'Jonah Hill', 'Josh Duhamel',\n",
       "       'Jude Law', 'Julia Louis-Dreyfus', 'Julie Bowen', 'Justin Long',\n",
       "       'Justine Bateman', 'Kal Penn', 'Karl Urban', 'Katrina Bowden',\n",
       "       'Kim Cattrall', 'Kristen Alderson', 'Kristin Chenoweth',\n",
       "       'Laura Leighton', 'Laurie Metcalf', 'Mark Wahlberg',\n",
       "       'Martin Sheen', 'Mary Beth Evans', 'Matt Dillon', 'Matt LeBlanc',\n",
       "       'Melissa Archer', 'Melissa Claire Egan', 'Michael Vartan',\n",
       "       'Michael Weatherly', 'Milo Ventimiglia', 'Neal McDonough',\n",
       "       'Neve Campbell', 'Nicolas Cage', \"Olivia d'Abo\",\n",
       "       'Pamela Sue Martin', 'Patrick Swayze', 'Peri Gilpin',\n",
       "       'Rachel Dratch', 'Rebecca Herbst', 'Robert Redford',\n",
       "       'Ryan Phillippe', 'Sarah Hyland', 'Selena Gomez', 'Shirley Jones',\n",
       "       'Steve Carell', 'T.J. Thyne', 'Taylor Atelian', 'Tia Carrere',\n",
       "       'Tobey Maguire', 'Tracey E. Bregman', 'Valerie Bertinelli',\n",
       "       'Yasmine Bleeth', 'Zooey Deschanel'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Subfolder",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "File Count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fa30ab9d-892b-4c91-9c37-4ed76855e7b9",
       "rows": [
        [
         "0",
         "Alan Arkin",
         "20"
        ],
        [
         "1",
         "Alan Rickman",
         "20"
        ],
        [
         "2",
         "Alyssa Milano",
         "20"
        ],
        [
         "3",
         "America Ferrera",
         "20"
        ],
        [
         "4",
         "Andrea Bowen",
         "18"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subfolder</th>\n",
       "      <th>File Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan Rickman</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Milano</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>America Ferrera</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andrea Bowen</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Subfolder  File Count\n",
       "0       Alan Arkin          20\n",
       "1     Alan Rickman          20\n",
       "2    Alyssa Milano          20\n",
       "3  America Ferrera          20\n",
       "4     Andrea Bowen          18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Sampleset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of row (images) : 106865\n"
     ]
    }
   ],
   "source": [
    "## import metadata\n",
    "facescrub_df_actor = pd.read_csv('faceScrub/facescrub_actors.txt',delimiter='\\t',header=None)\n",
    "facescrub_df_actress = pd.read_csv('faceScrub/facescrub_actresses.txt',delimiter='\\t',header=None)\n",
    "\n",
    "#combine dataframe\n",
    "facescrub_df=pd.concat([facescrub_df_actor,facescrub_df_actress],axis=0)\n",
    "\n",
    "print(f\"number of row (images) : {len(facescrub_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract the first row as the new header\n",
    "new_header = facescrub_df.iloc[0]\n",
    "\n",
    "# Step 2: Set the new header\n",
    "facescrub_df.columns = new_header\n",
    "\n",
    "# Step 3: Drop the first row (now redundant)\n",
    "df = facescrub_df[1:]\n",
    "\n",
    "# Reset index (optional)\n",
    "facescrub_df_new = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = facescrub_df_new[facescrub_df_new[\"name\"].isin(df_temp[\"Subfolder\"].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "image_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "face_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bbox",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sha256",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cf43aff7-825a-4d60-aae8-dedc4ee8e39a",
       "rows": [
        [
         "1419",
         "Alan Arkin",
         "2510",
         "1428",
         "http://upload.wikimedia.org/wikipedia/commons/0/02/Alan_Arkin_-_1975.jpg",
         "156,222,548,614",
         "3c97c0f369c05381631178667925ee9821ca271fe6feb7b6e3a88f2985e29e1e"
        ],
        [
         "1420",
         "Alan Arkin",
         "2511",
         "1429",
         "http://www.nndb.com/people/777/000022711/alan-arkin-sized.jpg",
         "57,25,172,140",
         "c38286df5ef80ca55cb5fddae185379acdb6db36bb8d11e3199e16a45f28b4a5"
        ],
        [
         "1421",
         "Alan Arkin",
         "2512",
         "1430",
         "http://ia.media-imdb.com/images/M/MV5BMjA4NDk5Njc3MF5BMl5BanBnXkFtZTYwNjc5NDc0._V1_SX640_SY720_.jpg",
         "26,85,243,302",
         "b4df4f3a91905799aff06f8564330b60d304a60389e02bb2769cff283d9ea273"
        ],
        [
         "1422",
         "Alan Arkin",
         "2514",
         "1431",
         "http://3.bp.blogspot.com/--qQ0lGtma_M/T3Dp7trnvAI/AAAAAAAAAG4/PK3Lad6VRXw/s1600/arkin.jpg",
         "74,52,232,210",
         "2d7e5907ef1d76f0e7c799cd3d4df01bc3ef7ad1ce44678d3ba336651363789a"
        ],
        [
         "1423",
         "Alan Arkin",
         "2515",
         "1432",
         "http://whatculture.com/wp-content/photos/Alan_Arkin.jpg",
         "81,16,193,128",
         "cf7f7569d842a5030662d37dde9d7fbc77ac4aa8fefe50caea4038b3f73d3e27"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image_id</th>\n",
       "      <th>face_id</th>\n",
       "      <th>url</th>\n",
       "      <th>bbox</th>\n",
       "      <th>sha256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2510</td>\n",
       "      <td>1428</td>\n",
       "      <td>http://upload.wikimedia.org/wikipedia/commons/...</td>\n",
       "      <td>156,222,548,614</td>\n",
       "      <td>3c97c0f369c05381631178667925ee9821ca271fe6feb7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2511</td>\n",
       "      <td>1429</td>\n",
       "      <td>http://www.nndb.com/people/777/000022711/alan-...</td>\n",
       "      <td>57,25,172,140</td>\n",
       "      <td>c38286df5ef80ca55cb5fddae185379acdb6db36bb8d11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2512</td>\n",
       "      <td>1430</td>\n",
       "      <td>http://ia.media-imdb.com/images/M/MV5BMjA4NDk5...</td>\n",
       "      <td>26,85,243,302</td>\n",
       "      <td>b4df4f3a91905799aff06f8564330b60d304a60389e02b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2514</td>\n",
       "      <td>1431</td>\n",
       "      <td>http://3.bp.blogspot.com/--qQ0lGtma_M/T3Dp7trn...</td>\n",
       "      <td>74,52,232,210</td>\n",
       "      <td>2d7e5907ef1d76f0e7c799cd3d4df01bc3ef7ad1ce4467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2515</td>\n",
       "      <td>1432</td>\n",
       "      <td>http://whatculture.com/wp-content/photos/Alan_...</td>\n",
       "      <td>81,16,193,128</td>\n",
       "      <td>cf7f7569d842a5030662d37dde9d7fbc77ac4aa8fefe50...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0           name image_id face_id  \\\n",
       "1419  Alan Arkin     2510    1428   \n",
       "1420  Alan Arkin     2511    1429   \n",
       "1421  Alan Arkin     2512    1430   \n",
       "1422  Alan Arkin     2514    1431   \n",
       "1423  Alan Arkin     2515    1432   \n",
       "\n",
       "0                                                   url             bbox  \\\n",
       "1419  http://upload.wikimedia.org/wikipedia/commons/...  156,222,548,614   \n",
       "1420  http://www.nndb.com/people/777/000022711/alan-...    57,25,172,140   \n",
       "1421  http://ia.media-imdb.com/images/M/MV5BMjA4NDk5...    26,85,243,302   \n",
       "1422  http://3.bp.blogspot.com/--qQ0lGtma_M/T3Dp7trn...    74,52,232,210   \n",
       "1423  http://whatculture.com/wp-content/photos/Alan_...    81,16,193,128   \n",
       "\n",
       "0                                                sha256  \n",
       "1419  3c97c0f369c05381631178667925ee9821ca271fe6feb7...  \n",
       "1420  c38286df5ef80ca55cb5fddae185379acdb6db36bb8d11...  \n",
       "1421  b4df4f3a91905799aff06f8564330b60d304a60389e02b...  \n",
       "1422  2d7e5907ef1d76f0e7c799cd3d4df01bc3ef7ad1ce4467...  \n",
       "1423  cf7f7569d842a5030662d37dde9d7fbc77ac4aa8fefe50...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "image_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "face_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "bbox",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sha256",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "48a85f2c-24c7-4761-8a70-02a9f56fbb35",
       "rows": [
        [
         "0",
         "Alan Arkin",
         "2850",
         "1638",
         "http://www.images99.com/i99/01/11318/11318.jpg",
         "183,47,291,155",
         "bc98b2174020a261ca4f8cd9b912f4087d3e1b2d7b4062a827e37216ca4d0c69"
        ],
        [
         "1",
         "Alan Arkin",
         "2845",
         "1637",
         "http://www.aceshowbiz.com/images/wennpic/newlander-arkin-24th-annual-palm-springs-international-film-festival-awards-gala-02.jpg",
         "394,47,508,161",
         "f83edaec4b768d29c284ccd52d17ad693712a93168b658d3740a0e1bcee17d55"
        ],
        [
         "2",
         "Alan Arkin",
         "2844",
         "1636",
         "http://www.superiorpics.com/wallpaper/file/Alan_Arkin_in_Get_Smart_Wallpaper_5_1280.jpg",
         "188,109,368,289",
         "4b100701994e3f658ca2d559600a7a4699d99259dfee0c7e28cac06257fbd6b9"
        ],
        [
         "3",
         "Alan Arkin",
         "2843",
         "1635",
         "http://famous-relationships.topsynergy.com/%21photos/Alan_Arkin.jpg",
         "24,38,138,152",
         "e9ce19ad6406a9a01b43921cdac2d86cd0ebc193f0df458bb862f09089defcb9"
        ],
        [
         "4",
         "Alan Arkin",
         "2842",
         "1634",
         "http://www.horsetrackhooligans.com/wp-content/uploads/2012/07/alan_arkin-204x300.jpg",
         "20,68,178,226",
         "70ef23aa0bfbc755732bd4762aa084492dba2c2142b7b6105ff9e9864f9710a1"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>image_id</th>\n",
       "      <th>face_id</th>\n",
       "      <th>url</th>\n",
       "      <th>bbox</th>\n",
       "      <th>sha256</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2850</td>\n",
       "      <td>1638</td>\n",
       "      <td>http://www.images99.com/i99/01/11318/11318.jpg</td>\n",
       "      <td>183,47,291,155</td>\n",
       "      <td>bc98b2174020a261ca4f8cd9b912f4087d3e1b2d7b4062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2845</td>\n",
       "      <td>1637</td>\n",
       "      <td>http://www.aceshowbiz.com/images/wennpic/newla...</td>\n",
       "      <td>394,47,508,161</td>\n",
       "      <td>f83edaec4b768d29c284ccd52d17ad693712a93168b658...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2844</td>\n",
       "      <td>1636</td>\n",
       "      <td>http://www.superiorpics.com/wallpaper/file/Ala...</td>\n",
       "      <td>188,109,368,289</td>\n",
       "      <td>4b100701994e3f658ca2d559600a7a4699d99259dfee0c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2843</td>\n",
       "      <td>1635</td>\n",
       "      <td>http://famous-relationships.topsynergy.com/%21...</td>\n",
       "      <td>24,38,138,152</td>\n",
       "      <td>e9ce19ad6406a9a01b43921cdac2d86cd0ebc193f0df45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alan Arkin</td>\n",
       "      <td>2842</td>\n",
       "      <td>1634</td>\n",
       "      <td>http://www.horsetrackhooligans.com/wp-content/...</td>\n",
       "      <td>20,68,178,226</td>\n",
       "      <td>70ef23aa0bfbc755732bd4762aa084492dba2c2142b7b6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0        name  image_id face_id  \\\n",
       "0  Alan Arkin      2850    1638   \n",
       "1  Alan Arkin      2845    1637   \n",
       "2  Alan Arkin      2844    1636   \n",
       "3  Alan Arkin      2843    1635   \n",
       "4  Alan Arkin      2842    1634   \n",
       "\n",
       "0                                                url             bbox  \\\n",
       "0     http://www.images99.com/i99/01/11318/11318.jpg   183,47,291,155   \n",
       "1  http://www.aceshowbiz.com/images/wennpic/newla...   394,47,508,161   \n",
       "2  http://www.superiorpics.com/wallpaper/file/Ala...  188,109,368,289   \n",
       "3  http://famous-relationships.topsynergy.com/%21...    24,38,138,152   \n",
       "4  http://www.horsetrackhooligans.com/wp-content/...    20,68,178,226   \n",
       "\n",
       "0                                             sha256  \n",
       "0  bc98b2174020a261ca4f8cd9b912f4087d3e1b2d7b4062...  \n",
       "1  f83edaec4b768d29c284ccd52d17ad693712a93168b658...  \n",
       "2  4b100701994e3f658ca2d559600a7a4699d99259dfee0c...  \n",
       "3  e9ce19ad6406a9a01b43921cdac2d86cd0ebc193f0df45...  \n",
       "4  70ef23aa0bfbc755732bd4762aa084492dba2c2142b7b6...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure 'image_id' is of numeric type for proper sorting\n",
    "filtered_df['image_id'] = pd.to_numeric(filtered_df['image_id'])\n",
    "\n",
    "# Sort by 'name' and then by 'image_id' in descending order\n",
    "filtered_df = filtered_df.sort_values(by=['name', 'image_id'], ascending=[True, False])\n",
    "\n",
    "# Reset index if needed\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_detect_faces(url, filename):\n",
    "    detector = MTCNN()\n",
    "    \n",
    "    try:\n",
    "\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Convert to numpy array \n",
    "        image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    \n",
    "        #check if image\n",
    "        if image is None:\n",
    "            return 0\n",
    "\n",
    "        # Detect faces in the image\n",
    "        result = detector.detect_faces(image)\n",
    "        if not len(result) ==1:\n",
    "            #print(f\"no face detected in {filename} number of face detected: {len(result)}\")\n",
    "            return 0\n",
    "            \n",
    "        # Only save the image if faces detected\n",
    "        cv2.imwrite(filename, image)\n",
    "        return 1\n",
    "        \n",
    "    except (requests.exceptions.RequestException, cv2.error) as e:\n",
    "        #remove image if not contain face\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                os.remove(filename)\n",
    "            except OSError:\n",
    "                pass\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                os.remove(filename)\n",
    "            except OSError:\n",
    "                pass\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def get_image_sample(ntest_person,nval_person,facescrub_df):\n",
    "    current_num_person = 0\n",
    "\n",
    "    list_person = []\n",
    "\n",
    "    for current_person in filtered_df[\"name\"].values:\n",
    "        \n",
    "        current_ntest_person = 0\n",
    "        current_nval_person = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        if current_person in list_person:\n",
    "            continue\n",
    "        else:\n",
    "        ##buat dataset dengan data orang tersebut\n",
    "            df_persons=facescrub_df[facescrub_df[0]==current_person]\n",
    "            \n",
    "            train_path = 'dataset/stagging/sampleset/'+current_person\n",
    "            val_path = 'dataset/stagging/validationset/'+current_person\n",
    "            test_path = 'dataset/stagging/testingset/'+current_person\n",
    "            ##buat folder untuk orang tersebut\n",
    "            if not os.path.exists(train_path):\n",
    "                \n",
    "                os.makedirs(train_path)\n",
    "            if not os.path.exists(test_path):\n",
    "                os.makedirs(test_path)\n",
    "\n",
    "            len_train = print(f\"dwonload image person={current_person} num_image={df_persons.shape[0]}\")\n",
    "            \n",
    "            \n",
    "            list_index_person=[]\n",
    "                    #get random index\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)\n",
    "                    ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_and_detect_faces(url, train_path+'/'+current_person+'_'+str(current_ntrain_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_ntrain_person+=1\n",
    "                        if current_ntrain_person % 10 == 0:\n",
    "                            print(f\"sample_person set image added for {current_person}: {current_ntrain_person}\")\n",
    "            while current_nval_person<nval_person:\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)    \n",
    "                     ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_and_detect_faces(url, val_path+'/'+current_person+'_'+str(current_nval_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_nval_person+=1\n",
    "                        if current_nval_person % 5 == 0:\n",
    "                            print(f\"val_person set image added for {current_person}: {current_nval_person}\")\n",
    "            while current_ntest_person<ntest_person:\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)    \n",
    "                     ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_and_detect_faces(url, test_path+'/'+current_person+'_'+str(current_ntest_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_ntest_person+=1\n",
    "                        if current_ntest_person % 5 == 0:\n",
    "                            print(f\"test_person set image added fro {current_person}: {current_ntest_person}\")\n",
    "            list_person.append(current_person)\n",
    "            current_num_person+=1\n",
    "            print(f\"===  Person added: {current_person} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/actress_face'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/actress_face\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset/actress_face'"
     ]
    }
   ],
   "source": [
    "os.listdir('dataset/actress_face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied Hank_Azaria: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Hector_Elizondo: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Rachel_Griffiths: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Mel_Gibson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied David_Schwimmer: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Antonio_Banderas: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Linda_Gray: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Cary_Elwes: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Staci_Keanan: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Katrina_Bowden: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jim_Carrey: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Alexander_Skarsgard: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Shannen_Doherty: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kevin_Connolly: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Richard_Madden: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Carey_Lowell: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Eliza_Coupe: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Dustin_Hoffman: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jude_Law: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Danny_Trejo: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Michael_Landes: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Nancy_Lee_Grahn: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Christopher_Lloyd: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Ben_Stiller: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kim_Fields: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Geoffrey_Rush: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Adrienne_Barbeau: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Melissa_Gilbert: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Roseanne_Barr: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Judi_Evans: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Michael_Weatherly: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Melissa_Benoist: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Elizabeth_Berkley: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Lexi_Ainsworth: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Daniel_Radcliffe: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Sasha_Alexander: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Mayim_Bialik: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Rebecca_Herbst: 20 sampleset, 5 testingset, 5 validationset\n",
      "Skipping Christina_Bennett_Lind - Not enough images (22/30).\n",
      "Copied James_Remar: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Anne_Hathaway: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Gerard_Butler: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jennifer_Aniston: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jeffrey_Tambor: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kristian_Alfonso: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Clive_Owen: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Molly_Burnett: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Judith_Light: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Orlando_Bloom: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kaley_Cuoco: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Florencia_Lozano: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Keanu_Reeves: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Ray_Stevenson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Bernie_Mac: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jason_Biggs: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Faith_Ford: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Marcia_Cross: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Channing_Tatum: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Hugo_Weaving: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jason_Lee: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Brooke_Langton: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Tina_Fey: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kirstie_Alley: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jean-Claude_Van_Damme: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Milo_Ventimiglia: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Portia_de_Rossi: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Joanna_Garcia: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kim_Cattrall: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Joe_Pantoliano: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Colin_Firth: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Emile_Hirsch: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Michael_Vartan: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Laurie_Metcalf: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Patricia_Kalember: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Julia_Louis-Dreyfus: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Leonardo_DiCaprio: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Lea_Michele: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Ben_Kingsley: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Sharon_Case: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Robert_Redford: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jack_Nicholson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jessica_Capshaw: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Audrey_Landers: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied January_Jones: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Shelley_Hennig: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Adam_Brody: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Lisa_Bonet: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Angie_Harmon: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jonathan_Rhys_Meyers: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kal_Penn: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Dina_Meyer: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Denise_Crosby: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Chase_Masterson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Joanna_Kerns: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Sean_Bean: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Bradley_Cooper: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Hugh_Jackman: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Tyne_Daly: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Burt_Reynolds: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Daniel_Day-Lewis: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Billy_Zane: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied John_Krasinski: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Rupert_Grint: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Peggy_Lipton: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Al_Pacino: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Lindsay_Hartley: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Dominic_Monaghan: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kathryn_Joosten: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied S._Epatha_Merkerson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jennifer_Love_Hewitt: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Holly_Marie_Combs: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Andrea_Bogart: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Aaron_Eckhart: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Mary_Crosby: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Josh_Hartnett: 20 sampleset, 5 testingset, 5 validationset\n",
      "Skipping Erin_Chambers - Not enough images (22/30).\n",
      "Copied Danny_Glover: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kathy_Baker: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Laura_Innes: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Richard_E._Grant: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Matthew_McConaughey: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied James_McAvoy: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Eliza_Dushku: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied John_Noble: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Liev_Schreiber: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jamie_Lee_Curtis: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Christel_Khalil: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Brendan_Fraser: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Brad_Pitt: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Mark_Wahlberg: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Patrick_Dempsey: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kristin_Davis: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Ian_McKellen: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jim_Beaver: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Owen_Wilson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Chris_Klein: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Drea_de_Matteo: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jane_Leeves: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Josh_Duhamel: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Tatyana_M._Ali: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Casey_Affleck: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Matt_LeBlanc: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Peggy_McCay: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Steve_Carell: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Mary_Beth_Evans: 20 sampleset, 5 testingset, 5 validationset\n",
      "Skipping Didi_Conn - Not enough images (29/30).\n",
      "Copied Zooey_Deschanel: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Richard_Gere: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jesse_Eisenberg: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Geena_Davis: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Giovanni_Ribisi: 20 sampleset, 5 testingset, 5 validationset\n",
      "Skipping Ashley_Johnson - Not enough images (26/30).\n",
      "Copied David_Cross: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kristy_McNichol: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jackie_Chan: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jason_Statham: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Edi_Gathegi: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Crystal_Bernard: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jane_Krakowski: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Portia_Doubleday: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Harry_Connick_Jr_: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Natalie_Hall: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Loni_Anderson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Jasmine_Guy: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Anthony_Hopkins: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Sharon_Gless: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied David_Boreanaz: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Gary_Dourdan: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Hal_Holbrook: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Oliver_Platt: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kristin_Chenoweth: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Sarah_Michelle_Gellar: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Ashton_Kutcher: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Katherine_Helmond: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kristen_Alderson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kathy_Griffin: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Justin_Long: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied George_Clooney: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Summer_Glau: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Clint_Eastwood: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kit_Harington: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Linda_Evans: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Kris_Kristofferson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied James_Marsden: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Ben_McKenzie: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Andy_Garcia: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Farrah_Fawcett: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied James_Brolin: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Robert_Duvall: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Harrison_Ford: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Joshua_Jackson: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Josie_Bissett: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Annie_Ilonzeh: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Laura_Leighton: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Natalia_Livingston: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Matt_Dillon: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Mila_Kunis: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Christian_Slater: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Melissa_Fumero: 20 sampleset, 5 testingset, 5 validationset\n",
      "Copied Shirley_Jones: 20 sampleset, 5 testingset, 5 validationset\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Old dataset paths (source)\n",
    "actor_path = \"dataset/actor_faces\"\n",
    "actress_path = \"dataset/actress_faces\"\n",
    "\n",
    "# New dataset paths (destination)\n",
    "new_sampleset_path = \"dataset/mtcnn_face_fix/sampleset\"\n",
    "new_testingset_path = \"dataset/mtcnn_face_fix/testingset\"\n",
    "new_validationset_path = \"dataset/mtcnn_face_fix/validationset\"\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path in [new_sampleset_path, new_testingset_path, new_validationset_path]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Collect all person folders from actor and actress directories\n",
    "person_folders = list(set(os.listdir(actor_path)) | set(os.listdir(actress_path)))  # Convert set to list\n",
    "\n",
    "# Randomly select 200 persons (or all if less than 200)\n",
    "selected_persons = random.sample(person_folders, min(200, len(person_folders)))\n",
    "\n",
    "# Function to organize images into the new dataset\n",
    "def organize_images(person_folder):\n",
    "    # Collect images from both actor and actress folders\n",
    "    all_images = []\n",
    "    for dataset_path in [actor_path, actress_path]:\n",
    "        person_path = os.path.join(dataset_path, person_folder)\n",
    "        if os.path.isdir(person_path):\n",
    "            all_images.extend([os.path.join(person_path, img) for img in os.listdir(person_path)])\n",
    "\n",
    "    # Ensure we have at least 30 images\n",
    "    if len(all_images) < 30:\n",
    "        print(f\"Skipping {person_folder} - Not enough images ({len(all_images)}/30).\")\n",
    "        return\n",
    "\n",
    "    # Shuffle images for randomness\n",
    "    random.shuffle(all_images)\n",
    "\n",
    "    # Assign 20 images to sampleset, 5 to testingset, 5 to validationset\n",
    "    sampleset_images = all_images[:20]\n",
    "    testingset_images = all_images[20:25]\n",
    "    validationset_images = all_images[25:30]\n",
    "\n",
    "    # Copy images to new directories\n",
    "    for img_list, target_path in zip([sampleset_images, testingset_images, validationset_images],\n",
    "                                     [new_sampleset_path, new_testingset_path, new_validationset_path]):\n",
    "        new_person_path = os.path.join(target_path, person_folder)\n",
    "        os.makedirs(new_person_path, exist_ok=True)\n",
    "\n",
    "        for img in img_list:\n",
    "            shutil.copy2(img, os.path.join(new_person_path, os.path.basename(img)))\n",
    "\n",
    "    print(f\"Copied {person_folder}: 20 sampleset, 5 testingset, 5 validationset\")\n",
    "\n",
    "# Process only the selected 200 persons\n",
    "for person in selected_persons:\n",
    "    organize_images(person)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
