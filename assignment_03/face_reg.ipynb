{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison of Face Recognition Models (Assignment 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from deepface import DeepFace\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of row (images) : 106865\n"
     ]
    }
   ],
   "source": [
    "## import metadata\n",
    "facescrub_df_actor = pd.read_csv('faceScrub/facescrub_actors.txt',delimiter='\\t',header=None)\n",
    "facescrub_df_actress = pd.read_csv('faceScrub/facescrub_actresses.txt',delimiter='\\t',header=None)\n",
    "\n",
    "#combine dataframe\n",
    "facescrub_df=pd.concat([facescrub_df_actor,facescrub_df_actress],axis=0)\n",
    "\n",
    "print(f\"number of row (images) : {len(facescrub_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique faces (people): 531\n",
      "            name  count\n",
      "0  Aaron Eckhart    231\n",
      "1     Adam Brody    200\n",
      "2     Adam McKay    108\n",
      "3   Adam Sandler    208\n",
      "4  Adrianne Le√≥n     62\n"
     ]
    }
   ],
   "source": [
    "# Group by the first column (name) and count the occurrences\n",
    "name_count_df = facescrub_df.groupby(facescrub_df.columns[0]).size().reset_index(name='count')\n",
    "\n",
    "# Rename the columns for clarity\n",
    "name_count_df.columns = ['name', 'count']\n",
    "name_count_df.head()\n",
    "# Display the new dataframe\n",
    "#name_count_df=name_count_df.sort_values(by='count', ascending=False)\n",
    "print(f\"number of unique faces (people): {len(name_count_df)}\")\n",
    "print(name_count_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_detect_faces(url, filename):\n",
    "    detector = MTCNN()\n",
    "    \n",
    "    try:\n",
    "\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Convert to numpy array \n",
    "        image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    \n",
    "        #check if image\n",
    "        if image is None:\n",
    "            return 0\n",
    "\n",
    "        # Detect faces in the image\n",
    "        result = detector.detect_faces(image)\n",
    "        if not len(result) ==1:\n",
    "            #print(f\"no face detected in {filename} number of face detected: {len(result)}\")\n",
    "            return 0\n",
    "            \n",
    "        # Only save the image if faces detected\n",
    "        cv2.imwrite(filename, image)\n",
    "        return 1\n",
    "        \n",
    "    except (requests.exceptions.RequestException, cv2.error) as e:\n",
    "        #remove image if not contain face\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                os.remove(filename)\n",
    "            except OSError:\n",
    "                pass\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                os.remove(filename)\n",
    "            except OSError:\n",
    "                pass\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def get_image_sample(num_person,ntrain_person,ntest_person,facescrub_df):\n",
    "    current_num_person = 0\n",
    "\n",
    "    list_person = []\n",
    "\n",
    "    while current_num_person<num_person:\n",
    "        current_ntrain_person = 0\n",
    "        current_ntest_person = 0\n",
    "        ##generate angka random sebagai index dari dataset\n",
    "        random_num = np.random.randint(0, facescrub_df.shape[0])\n",
    "        ##ambil nama orang dari dataset\n",
    "        \n",
    "        current_person=facescrub_df.iloc[random_num,0]\n",
    "        \n",
    "        if current_person in list_person:\n",
    "            continue\n",
    "        else:\n",
    "        ##buat dataset dengan data orang tersebut\n",
    "            df_persons=facescrub_df[facescrub_df[0]==current_person]\n",
    "            \n",
    "            train_path = 'dataset/stagging/sampleset/'+current_person\n",
    "            test_path = 'dataset/stagging/testingset/'+current_person\n",
    "            ##buat folder untuk orang tersebut\n",
    "            if not os.path.exists(train_path):\n",
    "                \n",
    "                os.makedirs(train_path)\n",
    "            if not os.path.exists(test_path):\n",
    "                os.makedirs(test_path)\n",
    "\n",
    "            len_train = print(f\"dwonload image person={current_person} num_image={df_persons.shape[0]}\")\n",
    "            \n",
    "            \n",
    "            list_index_person=[]\n",
    "            while current_ntrain_person<ntrain_person:\n",
    "                    #get random index\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)\n",
    "                    ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_and_detect_faces(url, train_path+'/'+current_person+'_'+str(current_ntrain_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_ntrain_person+=1\n",
    "                        if current_ntrain_person % 10 == 0:\n",
    "                            print(f\"sample_person set image added for {current_person}: {current_ntrain_person}\")\n",
    "            while current_ntest_person<ntest_person:\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)    \n",
    "                     ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_and_detect_faces(url, test_path+'/'+current_person+'_'+str(current_ntest_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_ntest_person+=1\n",
    "                        if current_ntest_person % 5 == 0:\n",
    "                            print(f\"test_person set image added fro {current_person}: {current_ntest_person}\")\n",
    "            list_person.append(current_person)\n",
    "            current_num_person+=1\n",
    "            print(f\"=== [{current_num_person}/{num_person}] Person added: {current_person} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwonload image person=Patrick Dempsey num_image=244\n",
      "sample_person set image added for Patrick Dempsey: 10\n",
      "sample_person set image added for Patrick Dempsey: 20\n",
      "test_person set image added fro Patrick Dempsey: 5\n",
      "=== [1/200] Person added: Patrick Dempsey ===\n",
      "dwonload image person=Justin Timberlake num_image=229\n",
      "sample_person set image added for Justin Timberlake: 10\n",
      "sample_person set image added for Justin Timberlake: 20\n",
      "test_person set image added fro Justin Timberlake: 5\n",
      "=== [2/200] Person added: Justin Timberlake ===\n",
      "dwonload image person=S. Epatha Merkerson num_image=208\n",
      "sample_person set image added for S. Epatha Merkerson: 10\n",
      "sample_person set image added for S. Epatha Merkerson: 20\n",
      "test_person set image added fro S. Epatha Merkerson: 5\n",
      "=== [3/200] Person added: S. Epatha Merkerson ===\n",
      "dwonload image person=Ben McKenzie num_image=203\n",
      "sample_person set image added for Ben McKenzie: 10\n",
      "sample_person set image added for Ben McKenzie: 20\n",
      "test_person set image added fro Ben McKenzie: 5\n",
      "=== [4/200] Person added: Ben McKenzie ===\n",
      "dwonload image person=Barbara Carrera num_image=160\n",
      "sample_person set image added for Barbara Carrera: 10\n",
      "sample_person set image added for Barbara Carrera: 20\n",
      "test_person set image added fro Barbara Carrera: 5\n",
      "=== [5/200] Person added: Barbara Carrera ===\n",
      "dwonload image person=Shelley Hack num_image=151\n",
      "sample_person set image added for Shelley Hack: 10\n",
      "sample_person set image added for Shelley Hack: 20\n",
      "test_person set image added fro Shelley Hack: 5\n",
      "=== [6/200] Person added: Shelley Hack ===\n",
      "dwonload image person=Rachel Dratch num_image=214\n",
      "sample_person set image added for Rachel Dratch: 10\n",
      "sample_person set image added for Rachel Dratch: 20\n",
      "test_person set image added fro Rachel Dratch: 5\n",
      "=== [7/200] Person added: Rachel Dratch ===\n",
      "dwonload image person=Bill Hader num_image=269\n",
      "sample_person set image added for Bill Hader: 10\n",
      "sample_person set image added for Bill Hader: 20\n",
      "test_person set image added fro Bill Hader: 5\n",
      "=== [8/200] Person added: Bill Hader ===\n",
      "dwonload image person=Ben Affleck num_image=259\n",
      "sample_person set image added for Ben Affleck: 10\n",
      "sample_person set image added for Ben Affleck: 20\n",
      "test_person set image added fro Ben Affleck: 5\n",
      "=== [9/200] Person added: Ben Affleck ===\n",
      "dwonload image person=James Brolin num_image=167\n",
      "sample_person set image added for James Brolin: 10\n",
      "sample_person set image added for James Brolin: 20\n",
      "test_person set image added fro James Brolin: 5\n",
      "=== [10/200] Person added: James Brolin ===\n",
      "dwonload image person=Ashley Jones num_image=258\n",
      "sample_person set image added for Ashley Jones: 10\n",
      "sample_person set image added for Ashley Jones: 20\n",
      "test_person set image added fro Ashley Jones: 5\n",
      "=== [11/200] Person added: Ashley Jones ===\n",
      "dwonload image person=Caroline Dhavernas num_image=232\n",
      "sample_person set image added for Caroline Dhavernas: 10\n",
      "sample_person set image added for Caroline Dhavernas: 20\n",
      "test_person set image added fro Caroline Dhavernas: 5\n",
      "=== [12/200] Person added: Caroline Dhavernas ===\n",
      "dwonload image person=Johnny Depp num_image=227\n",
      "sample_person set image added for Johnny Depp: 10\n",
      "sample_person set image added for Johnny Depp: 20\n",
      "test_person set image added fro Johnny Depp: 5\n",
      "=== [13/200] Person added: Johnny Depp ===\n",
      "dwonload image person=Eileen Davidson num_image=170\n",
      "sample_person set image added for Eileen Davidson: 10\n",
      "sample_person set image added for Eileen Davidson: 20\n",
      "test_person set image added fro Eileen Davidson: 5\n",
      "=== [14/200] Person added: Eileen Davidson ===\n",
      "dwonload image person=Charlie Sheen num_image=253\n",
      "sample_person set image added for Charlie Sheen: 10\n",
      "sample_person set image added for Charlie Sheen: 20\n",
      "test_person set image added fro Charlie Sheen: 5\n",
      "=== [15/200] Person added: Charlie Sheen ===\n",
      "dwonload image person=Chris Kattan num_image=190\n",
      "sample_person set image added for Chris Kattan: 10\n",
      "sample_person set image added for Chris Kattan: 20\n",
      "test_person set image added fro Chris Kattan: 5\n",
      "=== [16/200] Person added: Chris Kattan ===\n",
      "dwonload image person=Rob Schneider num_image=196\n",
      "sample_person set image added for Rob Schneider: 10\n",
      "sample_person set image added for Rob Schneider: 20\n",
      "test_person set image added fro Rob Schneider: 5\n",
      "=== [17/200] Person added: Rob Schneider ===\n",
      "dwonload image person=Debra Messing num_image=303\n",
      "sample_person set image added for Debra Messing: 10\n",
      "sample_person set image added for Debra Messing: 20\n",
      "test_person set image added fro Debra Messing: 5\n",
      "=== [18/200] Person added: Debra Messing ===\n",
      "dwonload image person=Angie Harmon num_image=272\n",
      "sample_person set image added for Angie Harmon: 10\n",
      "sample_person set image added for Angie Harmon: 20\n",
      "test_person set image added fro Angie Harmon: 5\n",
      "=== [19/200] Person added: Angie Harmon ===\n",
      "dwonload image person=Sally Field num_image=206\n",
      "sample_person set image added for Sally Field: 10\n",
      "sample_person set image added for Sally Field: 20\n",
      "test_person set image added fro Sally Field: 5\n",
      "=== [20/200] Person added: Sally Field ===\n",
      "dwonload image person=Rupert Friend num_image=192\n",
      "sample_person set image added for Rupert Friend: 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m##run function to get image sample\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mget_image_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_person\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mntrain_person\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mntest_person\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfacescrub_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacescrub_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 90\u001b[0m, in \u001b[0;36mget_image_sample\u001b[1;34m(num_person, ntrain_person, ntest_person, facescrub_df)\u001b[0m\n\u001b[0;32m     88\u001b[0m url \u001b[38;5;241m=\u001b[39m df_persons\u001b[38;5;241m.\u001b[39miloc[i,\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m##download gambar\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m isdownload\u001b[38;5;241m=\u001b[39m\u001b[43mdownload_and_detect_faces\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcurrent_person\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcurrent_ntrain_person\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isdownload\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     92\u001b[0m     current_ntrain_person\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m, in \u001b[0;36mdownload_and_detect_faces\u001b[1;34m(url, filename)\u001b[0m\n\u001b[0;32m      2\u001b[0m detector \u001b[38;5;241m=\u001b[39m MTCNN()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Convert to numpy array \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[0;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:495\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 495\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBrokenPipeError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:398\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 398\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\http\\client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1331\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\http\\client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1089\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer)\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1091\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1094\u001b[0m \n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1096\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1097\u001b[0m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\http\\client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:236\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n\u001b[0;32m    239\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_connected_to_proxy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\urllib3\\connection.py:196\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m:return: New socket connection.\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\urllib3\\util\\connection.py:81\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     79\u001b[0m         err \u001b[38;5;241m=\u001b[39m _\n\u001b[0;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m             \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\socket.py:500\u001b[0m, in \u001b[0;36msocket.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_real_close\u001b[39m(\u001b[38;5;28mself\u001b[39m, _ss\u001b[38;5;241m=\u001b[39m_socket\u001b[38;5;241m.\u001b[39msocket):\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;66;03m# This function should not reference any globals. See issue #808164.\u001b[39;00m\n\u001b[0;32m    498\u001b[0m     _ss\u001b[38;5;241m.\u001b[39mclose(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclose\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;66;03m# This function should not reference any globals. See issue #808164.\u001b[39;00m\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_refs \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##run function to get image sample\n",
    "get_image_sample(num_person=200,ntrain_person=20,ntest_person=5,facescrub_df=facescrub_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Organize folder(optional if all faces allready download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 200 persons.\n",
      "Processed Kassie_DePaiva: Train=20, Test=5\n",
      "Processed Bradley_Cooper: Train=20, Test=5\n",
      "Processed Cam_Gigandet: Train=20, Test=5\n",
      "Processed Audra_McDonald: Train=20, Test=5\n",
      "Processed Shannon_Kane: Train=20, Test=5\n",
      "Processed Crystal_Chappell: Train=20, Test=5\n",
      "Processed Jennette_McCurdy: Train=20, Test=5\n",
      "Processed John_Malkovich: Train=20, Test=5\n",
      "Processed Seth_Rogen: Train=20, Test=5\n",
      "Processed Kris_Kristofferson: Train=20, Test=5\n",
      "Processed John_Noble: Train=20, Test=5\n",
      "Processed Catherine_Bell: Train=20, Test=5\n",
      "Processed Sean_Bean: Train=20, Test=5\n",
      "Processed Alyssa_Milano: Train=20, Test=5\n",
      "Processed Jason_Behr: Train=20, Test=5\n",
      "Processed Martin_Sheen: Train=20, Test=5\n",
      "Processed Antonio_Banderas: Train=20, Test=5\n",
      "Processed Tempestt_Bledsoe: Train=20, Test=5\n",
      "Processed Ed_Harris: Train=20, Test=5\n",
      "Processed Valerie_Harper: Train=20, Test=5\n",
      "Processed Amaury_Nolasco: Train=20, Test=5\n",
      "Processed Oliver_Platt: Train=20, Test=5\n",
      "Processed Chyler_Leigh: Train=20, Test=5\n",
      "Processed Jensen_Ackles: Train=20, Test=5\n",
      "Processed Julie_Marie_Berman: Train=20, Test=5\n",
      "Processed Channing_Tatum: Train=20, Test=5\n",
      "Processed David_Boreanaz: Train=20, Test=5\n",
      "Processed Matthew_Lillard: Train=20, Test=5\n",
      "Processed Tia_Carrere: Train=20, Test=5\n",
      "Processed Tamala_Jones: Train=20, Test=5\n",
      "Processed Kim_Delaney: Train=20, Test=5\n",
      "Processed Marilu_Henner: Train=20, Test=5\n",
      "Processed Kimberlin_Brown: Train=20, Test=5\n",
      "Processed Kerr_Smith: Train=20, Test=5\n",
      "Processed Chris_Noth: Train=20, Test=5\n",
      "Processed Pamela_Sue_Martin: Train=20, Test=5\n",
      "Processed Sharon_Gless: Train=20, Test=5\n",
      "Processed Owen_Wilson: Train=20, Test=5\n",
      "Processed James_McAvoy: Train=20, Test=5\n",
      "Processed Victoria_Justice: Train=20, Test=5\n",
      "Processed Clint_Eastwood: Train=20, Test=5\n",
      "Processed Ryan_Gosling: Train=20, Test=5\n",
      "Processed Joanna_Kerns: Train=20, Test=5\n",
      "Processed Sarah_Drew: Train=20, Test=5\n",
      "Processed Julia_Louis-Dreyfus: Train=20, Test=5\n",
      "Processed Ryan_Phillippe: Train=20, Test=5\n",
      "Processed Kathy_Baker: Train=20, Test=5\n",
      "Processed Jonathan_Rhys_Meyers: Train=20, Test=5\n",
      "Processed Samuel_L._Jackson: Train=20, Test=5\n",
      "Processed Yasmine_Bleeth: Train=20, Test=5\n",
      "Processed Vanessa_Marcil: Train=20, Test=5\n",
      "Processed Peggy_Lipton: Train=20, Test=5\n",
      "Processed Amy_Davidson: Train=20, Test=5\n",
      "Processed Bill_Cosby: Train=20, Test=5\n",
      "Processed Shelley_Hennig: Train=20, Test=5\n",
      "Processed Ian_McKellen: Train=20, Test=5\n",
      "Processed January_Jones: Train=20, Test=5\n",
      "Processed Ellen_DeGeneres: Train=20, Test=5\n",
      "Processed Cheryl_Ladd: Train=20, Test=5\n",
      "Processed Kristen_Johnston: Train=20, Test=5\n",
      "Processed Lesley-Anne_Down: Train=20, Test=5\n",
      "Processed Andrea_Bogart: Train=20, Test=5\n",
      "Processed Barbara_Carrera: Train=20, Test=5\n",
      "Processed Jimmy_Fallon: Train=20, Test=5\n",
      "Processed Jean-Claude_Van_Damme: Train=20, Test=5\n",
      "Processed Debi_Mazar: Train=20, Test=5\n",
      "Processed Portia_de_Rossi: Train=20, Test=5\n",
      "Processed Robert_Knepper: Train=20, Test=5\n",
      "Processed Karl_Urban: Train=20, Test=5\n",
      "Processed Matt_Czuchry: Train=20, Test=5\n",
      "Processed Melissa_Archer: Train=20, Test=5\n",
      "Processed Summer_Glau: Train=20, Test=5\n",
      "Processed Ashley_Benson: Train=20, Test=5\n",
      "Processed Jerry_Seinfeld: Train=20, Test=5\n",
      "Processed S._Epatha_Merkerson: Train=20, Test=5\n",
      "Processed America_Ferrera: Train=20, Test=5\n",
      "Processed Matthew_Broderick: Train=20, Test=5\n",
      "Processed Liev_Schreiber: Train=20, Test=5\n",
      "Processed James_Brolin: Train=20, Test=5\n",
      "Processed Joaquin_Phoenix: Train=20, Test=5\n",
      "Processed David_Schwimmer: Train=20, Test=5\n",
      "Processed Candice_Bergen: Train=20, Test=5\n",
      "Processed Ellen_Greene: Train=20, Test=5\n",
      "Processed Laurie_Metcalf: Train=20, Test=5\n",
      "Processed Kiefer_Sutherland: Train=20, Test=5\n",
      "Processed Rachel_Griffiths: Train=20, Test=5\n",
      "Processed Kevin_McKidd: Train=20, Test=5\n",
      "Processed Casey_Affleck: Train=20, Test=5\n",
      "Processed Bonnie_Franklin: Train=20, Test=5\n",
      "Processed Matt_Long: Train=20, Test=5\n",
      "Processed Rebecca_Herbst: Train=20, Test=5\n",
      "Processed Jane_Curtin: Train=20, Test=5\n",
      "Processed Matthew_Perry: Train=20, Test=5\n",
      "Processed Allison_Janney: Train=20, Test=5\n",
      "Processed Colin_Farrell: Train=20, Test=5\n",
      "Processed Mel_Gibson: Train=20, Test=5\n",
      "Processed Dominic_Monaghan: Train=20, Test=5\n",
      "Processed Staci_Keanan: Train=20, Test=5\n",
      "Processed Katrina_Bowden: Train=20, Test=5\n",
      "Processed Nicolas_Cage: Train=20, Test=5\n",
      "Processed Jonathan_Sadowski: Train=20, Test=5\n",
      "Processed Matt_Damon: Train=20, Test=5\n",
      "Processed Dana_Delany: Train=20, Test=5\n",
      "Processed Christopher_Reeve: Train=20, Test=5\n",
      "Processed Julianna_Margulies: Train=20, Test=5\n",
      "Processed Florencia_Lozano: Train=20, Test=5\n",
      "Processed Jackee_Harry: Train=20, Test=5\n",
      "Processed Matthew_Gray_Gubler: Train=20, Test=5\n",
      "Processed Angell_Conwell: Train=20, Test=5\n",
      "Processed Tracey_Gold: Train=20, Test=5\n",
      "Processed Al_Pacino: Train=20, Test=5\n",
      "Processed Chris_Kattan: Train=20, Test=5\n",
      "Skipping Adrianne_LeoÃÅn, not enough images.\n",
      "Processed Joe_Pantoliano: Train=20, Test=5\n",
      "Processed Farah_Fath: Train=20, Test=5\n",
      "Processed Bill_Hader: Train=20, Test=5\n",
      "Processed Dustin_Hoffman: Train=20, Test=5\n",
      "Processed Melissa_Fumero: Train=20, Test=5\n",
      "Processed Carolyn_Hennesy: Train=20, Test=5\n",
      "Processed Patricia_Arquette: Train=20, Test=5\n",
      "Processed Orlando_Bloom: Train=20, Test=5\n",
      "Processed Lacey_Chabert: Train=20, Test=5\n",
      "Processed Robert_Patrick: Train=20, Test=5\n",
      "Processed Geena_Davis: Train=20, Test=5\n",
      "Processed Ray_Stevenson: Train=20, Test=5\n",
      "Processed George_Lopez: Train=20, Test=5\n",
      "Processed Morena_Baccarin: Train=20, Test=5\n",
      "Processed John_Cusack: Train=20, Test=5\n",
      "Processed Jude_Law: Train=20, Test=5\n",
      "Processed Eliza_Coupe: Train=20, Test=5\n",
      "Processed Patricia_Kalember: Train=20, Test=5\n",
      "Processed Susan_Dey: Train=20, Test=5\n",
      "Processed Lauren_Holly: Train=20, Test=5\n",
      "Processed Scott_Patterson: Train=20, Test=5\n",
      "Processed Luke_Wilson: Train=20, Test=5\n",
      "Processed Adrienne_Frantz: Train=20, Test=5\n",
      "Processed Christine_Lakin: Train=20, Test=5\n",
      "Processed Dean_Cain: Train=20, Test=5\n",
      "Processed Marcia_Cross: Train=20, Test=5\n",
      "Processed Carla_Gallo: Train=20, Test=5\n",
      "Processed Chris_Evans: Train=20, Test=5\n",
      "Processed Alec_Baldwin: Train=20, Test=5\n",
      "Processed Jackie_Chan: Train=20, Test=5\n",
      "Processed Richard_Madden: Train=20, Test=5\n",
      "Processed Richard_E._Grant: Train=20, Test=5\n",
      "Processed Omid_Djalili: Train=20, Test=5\n",
      "Processed Laura_Leighton: Train=20, Test=5\n",
      "Processed John_Krasinski: Train=20, Test=5\n",
      "Processed Kevin_Connolly: Train=20, Test=5\n",
      "Processed Jim_Carrey: Train=20, Test=5\n",
      "Processed Ken_Watanabe: Train=20, Test=5\n",
      "Processed Tatyana_M._Ali: Train=20, Test=5\n",
      "Processed Eliza_Dushku: Train=20, Test=5\n",
      "Processed Peter_Sarsgaard: Train=20, Test=5\n",
      "Processed Kristin_Chenoweth: Train=20, Test=5\n",
      "Processed Christopher_Lloyd: Train=20, Test=5\n",
      "Processed Dermot_Mulroney: Train=20, Test=5\n",
      "Processed Sasha_Alexander: Train=20, Test=5\n",
      "Processed Michael_Vartan: Train=20, Test=5\n",
      "Processed Robin_Williams: Train=20, Test=5\n",
      "Processed Roseanne_Barr: Train=20, Test=5\n",
      "Processed Brad_Pitt: Train=20, Test=5\n",
      "Processed Matt_Dillon: Train=20, Test=5\n",
      "Processed Jon_Voight: Train=20, Test=5\n",
      "Processed Natalie_Martinez: Train=20, Test=5\n",
      "Processed Leonardo_DiCaprio: Train=20, Test=5\n",
      "Processed Sherilyn_Fenn: Train=20, Test=5\n",
      "Processed Selena_Gomez: Train=20, Test=5\n",
      "Processed Julie_Bowen: Train=20, Test=5\n",
      "Processed Portia_Doubleday: Train=20, Test=5\n",
      "Processed Jamie_Lee_Curtis: Train=20, Test=5\n",
      "Processed Jared_Padalecki: Train=20, Test=5\n",
      "Processed Alan_Alda: Train=20, Test=5\n",
      "Processed Veronica_Hamel: Train=20, Test=5\n",
      "Processed Josh_Brolin: Train=20, Test=5\n",
      "Processed Clive_Owen: Train=20, Test=5\n",
      "Processed Didi_Conn: Train=20, Test=5\n",
      "Processed Danny_Masterson: Train=20, Test=5\n",
      "Processed Dwayne_Johnson: Train=20, Test=5\n",
      "Processed Anthony_Stewart_Head: Train=20, Test=5\n",
      "Processed Jon_Hamm: Train=20, Test=5\n",
      "Processed Aisha_Hinds: Train=20, Test=5\n",
      "Processed Kaley_Cuoco: Train=20, Test=5\n",
      "Processed Ioan_Gruffudd: Train=20, Test=5\n",
      "Processed Milo_Ventimiglia: Train=20, Test=5\n",
      "Processed Norman_Reedus: Train=20, Test=5\n",
      "Processed Lara_Flynn_Boyle: Train=20, Test=5\n",
      "Processed Arnold_Schwarzenegger: Train=20, Test=5\n",
      "Processed Justine_Bateman: Train=20, Test=5\n",
      "Processed Robert_Redford: Train=20, Test=5\n",
      "Processed Rue_McClanahan: Train=20, Test=5\n",
      "Processed Hector_Elizondo: Train=20, Test=5\n",
      "Processed J.K._Simmons: Train=20, Test=5\n",
      "Processed Chris_Rock: Train=20, Test=5\n",
      "Processed Adrienne_Barbeau: Train=20, Test=5\n",
      "Processed Jake_Gyllenhaal: Train=20, Test=5\n",
      "Processed Audrey_Landers: Train=20, Test=5\n",
      "Processed Jane_Krakowski: Train=20, Test=5\n",
      "Processed Andrea_Anders: Train=20, Test=5\n",
      "Processed Christian_Slater: Train=20, Test=5\n",
      "‚úÖ Dataset organized successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define paths\n",
    "base_folders = [\"dataset/actor_faces\", \"dataset/actress_faces\"]\n",
    "train_folder = \"dataset/stagging/sampleset\"\n",
    "test_folder = \"dataset/stagging/testingset\"\n",
    "\n",
    "# Function to clear and recreate a folder\n",
    "def reset_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)  # Delete everything inside\n",
    "    os.makedirs(folder_path)  # Recreate the empty folder\n",
    "\n",
    "# Reset train and test folders\n",
    "reset_folder(train_folder)\n",
    "reset_folder(test_folder)\n",
    "# Collect all person folders from both `actor_faces` and `actress_faces`\n",
    "all_persons = []\n",
    "for base_folder in base_folders:\n",
    "    if os.path.exists(base_folder):  # Ensure the folder exists before listing\n",
    "        persons = [os.path.join(base_folder, p) for p in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, p))]\n",
    "        all_persons.extend(persons)  # Add full paths\n",
    "\n",
    "#print(all_persons)\n",
    "# Randomly select up to 200 persons\n",
    "selected_persons = random.sample(all_persons, min(200, len(all_persons)))\n",
    "print(f\"Selected {len(selected_persons)} persons.\")\n",
    "\n",
    "# Process each selected person\n",
    "for person_path in selected_persons:\n",
    "    person_name = os.path.basename(person_path)  # Extract only folder name\n",
    "\n",
    "    images = [img for img in os.listdir(person_path) if img.endswith((\".jpeg\", \".jpg\", \".png\"))]\n",
    "\n",
    "    if len(images) < 20:  # Skip if not enough images\n",
    "        print(f\"Skipping {person_name}, not enough images.\")\n",
    "        continue\n",
    "\n",
    "    # Shuffle and select max 25 images\n",
    "    random.shuffle(images)\n",
    "    selected_images = images[:25]\n",
    "\n",
    "    # Split into train (20) and test (5)\n",
    "    train_images = selected_images[:20]\n",
    "    test_images = selected_images[20:]\n",
    "\n",
    "    # Create person folders in train and test\n",
    "    train_person_path = os.path.join(train_folder, person_name)\n",
    "    test_person_path = os.path.join(test_folder, person_name)\n",
    "    os.makedirs(train_person_path, exist_ok=True)\n",
    "    os.makedirs(test_person_path, exist_ok=True)\n",
    "\n",
    "    # Move images\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(person_path, img), os.path.join(train_person_path, img))\n",
    "\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(person_path, img), os.path.join(test_person_path, img))\n",
    "\n",
    "    print(f\"Processed {person_name}: Train={len(train_images)}, Test={len(test_images)}\")\n",
    "\n",
    "print(\"‚úÖ Dataset organized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Process Image with MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Najwan\\AppData\\Local\\Temp\\ipykernel_21972\\1042745916.py:2: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_mtcnn(detector,dirpath, dirdest):\n",
    "    \n",
    "    imagePaths = sorted(list(paths.list_images(dirpath)))\n",
    "    for imagePath in tqdm(imagePaths):\n",
    "        #path_split = imagePath.split(os.sep)\n",
    "        path_split=Path(imagePath).parts\n",
    "        name_person = path_split[-2]\n",
    "        fn = path_split[-1].split('.')\n",
    "        filename, fileformat = fn[0], fn[1]\n",
    "\n",
    "        os.makedirs(dirdest, exist_ok=True)\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(imagePath), cv2.COLOR_BGR2RGB)\n",
    "        result = detector.detect_faces(image)\n",
    "        #print(f\"Processing: {imagePath}, Faces detected: {len(result)}\")\n",
    "\n",
    "        for i in range(len(result)):\n",
    "            bounding_box = result[i]['box']\n",
    "            keypoints = result[i]['keypoints']\n",
    "\n",
    "            bounding_box[0] = max(0, bounding_box[0])\n",
    "            bounding_box[1] = max(0, bounding_box[1])\n",
    "\n",
    "            person_dir = os.path.join(dirdest, name_person)\n",
    "            os.makedirs(person_dir, exist_ok=True)\n",
    "            path_save = os.path.join(person_dir, f\"{filename}_{i}.{fileformat}\")\n",
    "            print(path_save)\n",
    "            img = image[bounding_box[1]:bounding_box[1] + bounding_box[3],\n",
    "                    bounding_box[0]:bounding_box[0] + bounding_box[2]]\n",
    "\n",
    "            cv2.imwrite(path_save, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "    print(\"Face detection and cropping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 2/100 [00:00<00:17,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9044_4231_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9045_4232_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 4/100 [00:00<00:14,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9059_4240_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9065_4243_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 6/100 [00:00<00:14,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9082_4252_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9096_4256_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 7/100 [00:01<00:14,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9119_4271_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 9/100 [00:01<00:14,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9124_4274_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9131_4278_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 11/100 [00:02<00:18,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9149_4286_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9154_4289_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 13/100 [00:02<00:16,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9187_4306_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9198_4310_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñå        | 15/100 [00:02<00:14,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9200_4312_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9213_4318_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 16/100 [00:02<00:15,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9232_4327_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 18/100 [00:03<00:15,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9238_4329_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9280_4352_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 20/100 [00:03<00:12,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9300_4362_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9341_4378_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà        | 21/100 [00:03<00:11,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58140_27673_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58149_27680_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 23/100 [00:04<00:12,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58157_27688_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58167_27697_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 25/100 [00:04<00:10,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58175_27703_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 27/100 [00:04<00:11,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58177_27704_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58185_27711_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 28/100 [00:04<00:12,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58192_27716_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 30/100 [00:05<00:12,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58200_27721_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58213_27729_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58218_27733_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [00:05<00:10,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58242_27754_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58249_27760_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58259_27767_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [00:06<00:09,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58280_27784_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58329_27821_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [00:06<00:08,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58338_27829_0.png\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58347_27835_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [00:06<00:08,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58377_27858_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [00:06<00:09,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58380_27861_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78813_35707_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [00:07<00:12,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78815_35709_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [00:07<00:12,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78819_35712_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78831_35719_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [00:07<00:09,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78833_35721_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78837_35723_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [00:08<00:11,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78843_35726_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [00:08<00:11,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78848_35727_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [00:08<00:11,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78851_35729_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78853_35731_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [00:09<00:10,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78858_35734_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78890_35746_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78894_35747_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78927_35758_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [00:10<00:06,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78934_35761_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78952_35771_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78977_35776_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [00:10<00:05,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78995_35784_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_79041_35796_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [00:10<00:05,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_79077_35803_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [00:10<00:08,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1800_964_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [00:11<00:09,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1814_975_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [00:11<00:09,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1844_999_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1852_1007_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [00:12<00:06,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1855_1008_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1856_1009_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [00:12<00:05,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1859_1012_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1879_1027_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [00:12<00:05,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1940_1062_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [00:12<00:05,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1952_1070_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [00:13<00:06,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1970_1076_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [00:13<00:06,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1992_1087_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [00:14<00:10,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2015_1101_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [00:14<00:11,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2034_1112_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [00:15<00:10,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2049_1120_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [00:15<00:10,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2095_1139_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [00:15<00:09,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2100_1141_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2111_1146_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [00:16<00:07,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2121_1151_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [00:16<00:06,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2122_1152_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [00:17<00:05,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2165_1180_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2192_1204_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [00:17<00:05,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2206_1215_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [00:17<00:04,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2207_1216_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [00:18<00:05,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2218_1222_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [00:18<00:04,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2224_1228_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [00:18<00:04,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2233_1235_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [00:19<00:03,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2256_1251_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2259_1253_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [00:19<00:03,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2297_1279_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [00:20<00:02,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2308_1287_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [00:20<00:02,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2321_1298_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [00:20<00:02,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2323_1300_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [00:21<00:02,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2352_1323_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [00:21<00:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2385_1345_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [00:21<00:01,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2389_1349_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [00:22<00:01,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2396_1354_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [00:22<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2442_1388_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [00:23<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2451_1395_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:23<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2490_1420_0.jpeg\n",
      "Face detection and cropping completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|‚ñç         | 1/25 [00:00<00:04,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 3/25 [00:00<00:06,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 4/25 [00:01<00:06,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:05,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58205_27724_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:05,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58230_27743_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:05,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58250_27761_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:05,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58301_27800_0.jpeg\n",
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58327_27819_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:04,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_78817_35710_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:03,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_78942_35766_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:03,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_78981_35777_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:03,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_79048_35798_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:02,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_79128_35809_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:02,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_1833_992_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:02,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_1867_1018_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_1973_1077_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_1976_1078_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:01,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_2008_1096_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2173_1188_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2209_1218_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2225_1229_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:07<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2342_1315_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:07<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2408_1362_0.jpeg\n",
      "Face detection and cropping completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dirpaths=['dataset/stagging/sampleset','dataset/stagging/testingset']\n",
    "\n",
    "for dirpath in dirpaths:\n",
    "    processed_mtcnn(detector=MTCNN(),dirpath=dirpath,dirdest=dirpath.replace(\"stagging\",\"mtcnn_faces\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Face Verification with DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_face(img1path, img2path, model_name= \"Facenet\", distance_metric=\"cosine\", threshold=0.4):\n",
    "    if not os.path.exists(img1path) or not os.path.exists(img2path):\n",
    "        print(f\"Error: One or both images not found: {img1path}, {img2path}\")\n",
    "        return False, None\n",
    "    \n",
    "    else:\n",
    "        img1path = img1path.replace(\"\\\\\", \"/\")\n",
    "        img2path = img2path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "        #print(f\"Verifying: {img1path} vs {img2path}\")\n",
    "        result = DeepFace.verify(\n",
    "            img1_path=img1path,\n",
    "            img2_path=img2path,\n",
    "            model_name=model_name,\n",
    "            distance_metric='cosine',\n",
    "            threshold=0.4,\n",
    "            enforce_detection=False\n",
    "        )\n",
    "        #print(result)\n",
    "        return result[\"verified\"], result[\"distance\"]\n",
    "\n",
    "def evaluate_performance(train_dir, test_dir):\n",
    "    \n",
    "    results = []\n",
    "    def get_all_path_person(folder):\n",
    "        images = []\n",
    "        for person in os.listdir(folder):\n",
    "            person_dir = os.path.join(folder, person) # return: dataset/mtcnn_faces/sampleset/person_name\n",
    "            # Skip if not a directory\n",
    "            #print(person_dir)\n",
    "            if not os.path.isdir(person_dir):\n",
    "                continue\n",
    "            # Initialize person entry\n",
    "            person_images = {'person': person, 'path': []}\n",
    "            # Collect all image paths for this person\n",
    "            for file in os.listdir(person_dir):\n",
    "                file_path = os.path.join(person_dir, file)\n",
    "                person_images['path'].append(file_path)\n",
    "            # Add to the main list\n",
    "            images.append(person_images)\n",
    "            #print(images)\n",
    "        return images\n",
    "    \n",
    "    train_images_set = get_all_path_person(train_dir)\n",
    "    test_images_set = get_all_path_person(test_dir)\n",
    "    \n",
    "    if not train_images_set or not test_images_set:\n",
    "        print(\"Warning: One or both directories are empty!\")\n",
    "    for train_person in train_images_set:\n",
    "        for test_person in test_images_set:\n",
    "            print(f\"Verifying: {train_person['person']} vs {test_person['person']}\")\n",
    "            if train_person['person'] == test_person['person']:\n",
    "                for train_img in train_person['path']:\n",
    "                    for test_img in test_person['path']:\n",
    "                        print(f\"Comparing: {train_img} vs {test_img}\")\n",
    "                        verified, distance = verify_face(train_img, test_img, threshold=0.4)\n",
    "                        results.append({'train': train_img, \n",
    "                                        'test': test_img, \n",
    "                                        'verified': verified,\n",
    "                                        'y_true':#if same folder then 1 else 0,\n",
    "                                        'y_pred': #1 if verified else 0,\n",
    "                                        'distance': distance})\n",
    "\n",
    "            else:\n",
    "                continue \n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_face(img1path, img2path, model_name=\"Facenet\", distance_metric=\"cosine\", threshold=0.4):\n",
    "    \"\"\"Verifies if two faces belong to the same person.\"\"\"\n",
    "    if not os.path.exists(img1path) or not os.path.exists(img2path):\n",
    "        print(f\"Error: One or both images not found: {img1path}, {img2path}\")\n",
    "        return False, None\n",
    "    \n",
    "    result = DeepFace.verify(\n",
    "        img1_path=img1path,\n",
    "        img2_path=img2path,\n",
    "        model_name=model_name,\n",
    "        distance_metric=distance_metric,\n",
    "        threshold=threshold,\n",
    "        enforce_detection=False\n",
    "    )\n",
    "    return result[\"verified\"], result[\"distance\"]\n",
    "\n",
    "def get_all_path_person(folder):\n",
    "    \"\"\"Retrieves all image paths for each person in a given dataset folder.\"\"\"\n",
    "    persons = []\n",
    "    for person in os.listdir(folder):\n",
    "        person_dir = os.path.join(folder, person)\n",
    "        if not os.path.isdir(person_dir): \n",
    "            continue  # Skip non-directory files\n",
    "        person_images = {\n",
    "            'person': person,\n",
    "            'path': [os.path.join(person_dir, file) for file in os.listdir(person_dir)]\n",
    "        }\n",
    "        persons.append(person_images)\n",
    "    return persons\n",
    "\n",
    "def evaluate_performance(train_dir, test_dir, same_person_samples=5, diff_person_samples=5):\n",
    "    \"\"\"\n",
    "    Evaluates face verification performance with balanced same-person and different-person comparisons.\n",
    "    Optimized for large datasets.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    train_images_set = get_all_path_person(train_dir)\n",
    "    test_images_set = get_all_path_person(test_dir)\n",
    "\n",
    "    if not train_images_set or not test_images_set:\n",
    "        print(\"Warning: One or both directories are empty!\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Create a dictionary mapping person names to their image paths\n",
    "    train_dict = {p[\"person\"]: p[\"path\"] for p in train_images_set}\n",
    "    test_dict = {p[\"person\"]: p[\"path\"] for p in test_images_set}\n",
    "    \n",
    "    train_persons = list(train_dict.keys())\n",
    "    test_persons = list(test_dict.keys())\n",
    "\n",
    "    for test_person in test_persons:\n",
    "        if test_person in train_dict:\n",
    "            # Sample images for same-person verification\n",
    "            train_sample = random.sample(train_dict[test_person], min(same_person_samples, len(train_dict[test_person])))\n",
    "            test_sample = random.sample(test_dict[test_person], min(same_person_samples, len(test_dict[test_person])))\n",
    "\n",
    "            for train_img, test_img in zip(train_sample, test_sample):\n",
    "                verified, distance = verify_face(train_img, test_img, threshold=0.4)\n",
    "                results.append({\n",
    "                    'train': train_img, 'test': test_img,\n",
    "                    'verified': verified, 'y_true': 1, 'y_pred': int(verified), 'distance': distance\n",
    "                })\n",
    "\n",
    "        # Sample different persons for non-matching verification\n",
    "        non_matching_persons = [p for p in train_persons if p != test_person]\n",
    "        random_non_matching = random.sample(non_matching_persons, diff_person_samples)  # Pick 5 different persons\n",
    "\n",
    "        for other_person in random_non_matching:\n",
    "            random_train_img = random.choice(train_dict[other_person])\n",
    "            random_test_img = random.choice(test_dict[test_person])\n",
    "            \n",
    "            verified, distance = verify_face(random_train_img, random_test_img, threshold=0.4)\n",
    "            results.append({\n",
    "                'train': random_train_img, 'test': random_test_img,\n",
    "                'verified': verified, 'y_true': 0, 'y_pred': int(verified), 'distance': distance\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying: Adrienne_Barbeau vs Adrienne_Barbeau\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9044_4231_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9044_4231_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9044_4231_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9044_4231_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9044_4231_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9045_4232_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9045_4232_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9045_4232_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9045_4232_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9045_4232_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9059_4240_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9059_4240_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9059_4240_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9059_4240_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9059_4240_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9065_4243_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9065_4243_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9065_4243_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9065_4243_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9065_4243_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9082_4252_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9082_4252_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9082_4252_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9082_4252_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9082_4252_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9096_4256_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9096_4256_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9096_4256_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9096_4256_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9096_4256_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9119_4271_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9119_4271_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9119_4271_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9119_4271_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9119_4271_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9124_4274_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9124_4274_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9124_4274_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9124_4274_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9124_4274_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9131_4278_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9131_4278_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9131_4278_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9131_4278_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9131_4278_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9149_4286_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9149_4286_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9149_4286_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9149_4286_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9149_4286_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9154_4289_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9154_4289_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9154_4289_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9154_4289_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n",
      "Comparing: dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9154_4289_0.jpeg vs dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_performance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/mtcnn_faces/sampleset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdataset/mtcnn_faces/testingset\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(results\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[51], line 56\u001b[0m, in \u001b[0;36mevaluate_performance\u001b[1;34m(train_dir, test_dir)\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m test_img \u001b[38;5;129;01min\u001b[39;00m test_person[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     55\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComparing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_img\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_img\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m             verified, distance \u001b[38;5;241m=\u001b[39m \u001b[43mverify_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m             results\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: train_img, \n\u001b[0;32m     58\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: test_img, \n\u001b[0;32m     59\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m'\u001b[39m: verified, \n\u001b[0;32m     60\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m: distance})\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[51], line 11\u001b[0m, in \u001b[0;36mverify_face\u001b[1;34m(img1path, img2path, model_name, distance_metric, threshold)\u001b[0m\n\u001b[0;32m      8\u001b[0m img2path \u001b[38;5;241m=\u001b[39m img2path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#print(f\"Verifying: {img1path} vs {img2path}\")\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDeepFace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg1path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg2path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#print(result)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverified\u001b[39m\u001b[38;5;124m\"\u001b[39m], result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\deepface\\DeepFace.py:150\u001b[0m, in \u001b[0;36mverify\u001b[1;34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mverify\u001b[39m(\n\u001b[0;32m     71\u001b[0m     img1_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, List[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[0;32m     72\u001b[0m     img2_path: Union[\u001b[38;5;28mstr\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray, List[\u001b[38;5;28mfloat\u001b[39m]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m     anti_spoofing: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     83\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;124;03m    Verify if an image pair represents the same person or different persons.\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m        - 'time' (float): Time taken for the verification process in seconds.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mverification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg1_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg1_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg2_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistance_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistance_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\deepface\\modules\\verification.py:182\u001b[0m, in \u001b[0;36mverify\u001b[1;34m(img1_path, img2_path, model_name, detector_backend, distance_metric, enforce_detection, align, expand_percentage, normalization, silent, threshold, anti_spoofing)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img_embeddings, img_facial_areas\n\u001b[0;32m    181\u001b[0m img1_embeddings, img1_facial_areas \u001b[38;5;241m=\u001b[39m extract_embeddings_and_facial_areas(img1_path, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 182\u001b[0m img2_embeddings, img2_facial_areas \u001b[38;5;241m=\u001b[39m \u001b[43mextract_embeddings_and_facial_areas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg2_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m min_distance, min_idx, min_idy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, img1_embedding \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(img1_embeddings):\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\deepface\\modules\\verification.py:167\u001b[0m, in \u001b[0;36mverify.<locals>.extract_embeddings_and_facial_areas\u001b[1;34m(img_path, index)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m         img_embeddings, img_facial_areas \u001b[38;5;241m=\u001b[39m \u001b[43m__extract_faces_and_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetector_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpand_percentage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_percentage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43manti_spoofing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43manti_spoofing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException while processing img\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_path\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\deepface\\modules\\verification.py:248\u001b[0m, in \u001b[0;36m__extract_faces_and_embeddings\u001b[1;34m(img_path, model_name, detector_backend, enforce_detection, align, expand_percentage, normalization, anti_spoofing)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m anti_spoofing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m img_obj\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_real\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpoof detected in given image.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 248\u001b[0m img_embedding_obj \u001b[38;5;241m=\u001b[39m \u001b[43mrepresentation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepresent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_obj\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mface\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_detection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_detection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mskip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnormalization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# already extracted face given, safe to access its 1st item\u001b[39;00m\n\u001b[0;32m    257\u001b[0m img_embedding \u001b[38;5;241m=\u001b[39m img_embedding_obj[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\deepface\\modules\\representation.py:133\u001b[0m, in \u001b[0;36mrepresent\u001b[1;34m(img_path, model_name, enforce_detection, detector_backend, align, expand_percentage, normalization, anti_spoofing, max_faces)\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;66;03m# custom normalization\u001b[39;00m\n\u001b[0;32m    131\u001b[0m     img \u001b[38;5;241m=\u001b[39m preprocessing\u001b[38;5;241m.\u001b[39mnormalize_input(img\u001b[38;5;241m=\u001b[39mimg, normalization\u001b[38;5;241m=\u001b[39mnormalization)\n\u001b[1;32m--> 133\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m     resp_objs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    136\u001b[0m         {\n\u001b[0;32m    137\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m: embedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    140\u001b[0m         }\n\u001b[0;32m    141\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp_objs\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\deepface\\models\\FacialRecognition.py:29\u001b[0m, in \u001b[0;36mFacialRecognition.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must overwrite forward method if it is not a keras model,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not overwritten!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# model.predict causes memory issue when it is called in a for loop\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# embedding = model.predict(img, verbose=0)[0].tolist()\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:899\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:46\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[0;32m     42\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[0;32m     43\u001b[0m         call_fn,\n\u001b[0;32m     44\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     45\u001b[0m     )\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:182\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m             backend\u001b[38;5;241m.\u001b[39mset_keras_mask(x, mask)\n\u001b[1;32m--> 182\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_through_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moperation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unpack_singleton(outputs)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\function.py:171\u001b[0m, in \u001b[0;36mFunction._run_through_graph\u001b[1;34m(self, inputs, operation_fn, call_fn)\u001b[0m\n\u001b[0;32m    169\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m call_fn(op, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(node\u001b[38;5;241m.\u001b[39moutputs, tree\u001b[38;5;241m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\models\\functional.py:584\u001b[0m, in \u001b[0;36moperation_fn.<locals>.call\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(operation, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_call_has_training_arg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m operation\u001b[38;5;241m.\u001b[39m_call_has_training_arg\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    582\u001b[0m ):\n\u001b[0;32m    583\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m training\n\u001b[1;32m--> 584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moperation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\layer.py:899\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# Change the layout for the layer output if needed.\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# This is useful for relayout intermediate tensor in the model\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# to achieve the optimal performance.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m distribution \u001b[38;5;241m=\u001b[39m distribution_lib\u001b[38;5;241m.\u001b[39mdistribution()\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\operation.py:46\u001b[0m, in \u001b[0;36mOperation.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m             call_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall\n\u001b[0;32m     42\u001b[0m     call_fn \u001b[38;5;241m=\u001b[39m traceback_utils\u001b[38;5;241m.\u001b[39minject_argument_info_in_traceback(\n\u001b[0;32m     43\u001b[0m         call_fn,\n\u001b[0;32m     44\u001b[0m         object_name\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.call()\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     45\u001b[0m     )\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:156\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:252\u001b[0m, in \u001b[0;36mBatchNormalization.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    249\u001b[0m inputs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(inputs, compute_dtype)\n\u001b[0;32m    251\u001b[0m moving_mean \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoving_mean, inputs\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m--> 252\u001b[0m moving_variance \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoving_variance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable:\n\u001b[0;32m    255\u001b[0m     mean, variance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_moments(inputs, mask)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\ops\\core.py:802\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype)\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x,)):\n\u001b[0;32m    801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Cast(dtype\u001b[38;5;241m=\u001b[39mdtype)(x)\n\u001b[1;32m--> 802\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:189\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1012\u001b[0m, in \u001b[0;36mcast\u001b[1;34m(x, dtype, name)\u001b[0m\n\u001b[0;32m   1006\u001b[0m   x \u001b[38;5;241m=\u001b[39m indexed_slices\u001b[38;5;241m.\u001b[39mIndexedSlices(values_cast, x\u001b[38;5;241m.\u001b[39mindices, x\u001b[38;5;241m.\u001b[39mdense_shape)\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1008\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): If x is not already a Tensor, we could return\u001b[39;00m\n\u001b[0;32m   1009\u001b[0m   \u001b[38;5;66;03m# ops.convert_to_tensor(x, dtype=dtype, ...)  here, but that\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m   \u001b[38;5;66;03m# allows some conversions that cast() can't do, e.g. casting numbers to\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m   \u001b[38;5;66;03m# strings.\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mis_complex \u001b[38;5;129;01mand\u001b[39;00m base_type\u001b[38;5;241m.\u001b[39mis_floating:\n\u001b[0;32m   1014\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are casting an input of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to an \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1016\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_type\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.  This will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscard the imaginary part and may not be what you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintended.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:732\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[0;32m    731\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[1;32m--> 732\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:209\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    207\u001b[0m overload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__tf_tensor__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m overload \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moverload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#  pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m base_type, conversion_func \u001b[38;5;129;01min\u001b[39;00m get(\u001b[38;5;28mtype\u001b[39m(value)):\n\u001b[0;32m    212\u001b[0m   \u001b[38;5;66;03m# If dtype is None but preferred_dtype is not None, we try to\u001b[39;00m\n\u001b[0;32m    213\u001b[0m   \u001b[38;5;66;03m# cast to preferred_dtype first.\u001b[39;00m\n\u001b[0;32m    214\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:77\u001b[0m, in \u001b[0;36mVariable.__tf_tensor__\u001b[1;34m(self, dtype, name)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__tf_tensor__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:2375\u001b[0m, in \u001b[0;36m_dense_var_to_tensor\u001b[1;34m(var, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m   2374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dense_var_to_tensor\u001b[39m(var, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 2375\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dense_var_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1621\u001b[0m, in \u001b[0;36mBaseResourceVariable._dense_var_to_tensor\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1619\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_value()\u001b[38;5;241m.\u001b[39mop\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1621\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:656\u001b[0m, in \u001b[0;36mBaseResourceVariable.value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    654\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_value\n\u001b[0;32m    655\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28;01mNone\u001b[39;00m, ignore_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 656\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:841\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    839\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    844\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    845\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    846\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    847\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    848\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    849\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:831\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    830\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 831\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Najwa\\miniconda3\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:590\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    589\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 590\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    593\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = evaluate_performance(train_dir='dataset/mtcnn_faces/sampleset', test_dir='dataset/mtcnn_faces/testingset')\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5a96b68d-e3c5-4ac5-ae18-5fa40d647990",
       "rows": [],
       "shape": {
        "columns": 0,
        "rows": 0
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
