{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison of Face Recognition Models (Assignment 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of row (images) : 106865\n"
     ]
    }
   ],
   "source": [
    "## import metadata\n",
    "facescrub_df_actor = pd.read_csv('faceScrub/facescrub_actors.txt',delimiter='\\t',header=None)\n",
    "facescrub_df_actress = pd.read_csv('faceScrub/facescrub_actresses.txt',delimiter='\\t',header=None)\n",
    "\n",
    "#combine dataframe\n",
    "facescrub_df=pd.concat([facescrub_df_actor,facescrub_df_actress],axis=0)\n",
    "\n",
    "print(f\"number of row (images) : {len(facescrub_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique faces (people): 531\n",
      "            name  count\n",
      "0  Aaron Eckhart    231\n",
      "1     Adam Brody    200\n",
      "2     Adam McKay    108\n",
      "3   Adam Sandler    208\n",
      "4  Adrianne León     62\n"
     ]
    }
   ],
   "source": [
    "# Group by the first column (name) and count the occurrences\n",
    "name_count_df = facescrub_df.groupby(facescrub_df.columns[0]).size().reset_index(name='count')\n",
    "\n",
    "# Rename the columns for clarity\n",
    "name_count_df.columns = ['name', 'count']\n",
    "name_count_df.head()\n",
    "# Display the new dataframe\n",
    "#name_count_df=name_count_df.sort_values(by='count', ascending=False)\n",
    "print(f\"number of unique faces (people): {len(name_count_df)}\")\n",
    "print(name_count_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, filename):\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, timeout=10, stream=True)\n",
    "        #print(f\"Status Code: {response.status_code}\")\n",
    "        response.raise_for_status()  # Raises an error for HTTP issues\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in response.iter_content(1024):\n",
    "                f.write(chunk)\n",
    "        #print(\"Download complete!\")\n",
    "        return 1\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        #print(f\"Error: {e}\")\n",
    "        #print(\"Download failed.\")\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def get_image_sample(num_person,ntrain_person,ntest_person,facescrub_df):\n",
    "    current_num_person = 0\n",
    "\n",
    "    list_person = []\n",
    "\n",
    "    while current_num_person<num_person:\n",
    "        current_ntrain_person = 0\n",
    "        current_ntest_person = 0\n",
    "        ##generate angka random sebagai index dari dataset\n",
    "        random_num = np.random.randint(0, facescrub_df.shape[0])\n",
    "        ##ambil nama orang dari dataset\n",
    "        \n",
    "        current_person=facescrub_df.iloc[random_num,0]\n",
    "        \n",
    "        if current_person in list_person:\n",
    "            continue\n",
    "        else:\n",
    "        ##buat dataset dengan data orang tersebut\n",
    "            df_persons=facescrub_df[facescrub_df[0]==current_person]\n",
    "            \n",
    "            train_path = 'dataset/stagging/sampleset/'+current_person\n",
    "            test_path = 'dataset/stagging/testingset/'+current_person\n",
    "            ##buat folder untuk orang tersebut\n",
    "            if not os.path.exists(train_path):\n",
    "                \n",
    "                os.makedirs(train_path)\n",
    "            if not os.path.exists(test_path):\n",
    "                os.makedirs(test_path)\n",
    "\n",
    "            len_train = print(f\"dwonload image person={current_person} num_image={df_persons.shape[0]}\")\n",
    "            \n",
    "            \n",
    "            list_index_person=[]\n",
    "            while current_ntrain_person<ntrain_person:\n",
    "                    #get random index\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)\n",
    "                    ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_image(url, train_path+'/'+current_person+'_'+str(current_ntrain_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_ntrain_person+=1\n",
    "                        if current_ntrain_person % 10 == 0:\n",
    "                            print(f\"sample_person set image added for {current_person}: {current_ntrain_person}\")\n",
    "            while current_ntest_person<ntest_person:\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)    \n",
    "                     ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_image(url, test_path+'/'+current_person+'_'+str(current_ntest_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_ntest_person+=1\n",
    "                        if current_ntest_person % 5 == 0:\n",
    "                            print(f\"test_person set image added fro {current_person}: {current_ntest_person}\")\n",
    "            list_person.append(current_person)\n",
    "            current_num_person+=1\n",
    "            print(f\"=== [{current_num_person}/{num_person}] Person added: {current_person} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwonload image person=Hugh Jackman num_image=211\n",
      "sample_person set image added for Hugh Jackman: 10\n",
      "sample_person set image added for Hugh Jackman: 20\n",
      "test_person set image added fro Hugh Jackman: 5\n",
      "=== [1/1] Person added: Hugh Jackman ===\n"
     ]
    }
   ],
   "source": [
    "##run function to get image sample\n",
    "get_image_sample(num_person=1,ntrain_person=20,ntest_person=5,facescrub_df=facescrub_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Organize folder(optional if all faces allready download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 200 persons.\n",
      "Processed Kassie_DePaiva: Train=20, Test=5\n",
      "Processed Bradley_Cooper: Train=20, Test=5\n",
      "Processed Cam_Gigandet: Train=20, Test=5\n",
      "Processed Audra_McDonald: Train=20, Test=5\n",
      "Processed Shannon_Kane: Train=20, Test=5\n",
      "Processed Crystal_Chappell: Train=20, Test=5\n",
      "Processed Jennette_McCurdy: Train=20, Test=5\n",
      "Processed John_Malkovich: Train=20, Test=5\n",
      "Processed Seth_Rogen: Train=20, Test=5\n",
      "Processed Kris_Kristofferson: Train=20, Test=5\n",
      "Processed John_Noble: Train=20, Test=5\n",
      "Processed Catherine_Bell: Train=20, Test=5\n",
      "Processed Sean_Bean: Train=20, Test=5\n",
      "Processed Alyssa_Milano: Train=20, Test=5\n",
      "Processed Jason_Behr: Train=20, Test=5\n",
      "Processed Martin_Sheen: Train=20, Test=5\n",
      "Processed Antonio_Banderas: Train=20, Test=5\n",
      "Processed Tempestt_Bledsoe: Train=20, Test=5\n",
      "Processed Ed_Harris: Train=20, Test=5\n",
      "Processed Valerie_Harper: Train=20, Test=5\n",
      "Processed Amaury_Nolasco: Train=20, Test=5\n",
      "Processed Oliver_Platt: Train=20, Test=5\n",
      "Processed Chyler_Leigh: Train=20, Test=5\n",
      "Processed Jensen_Ackles: Train=20, Test=5\n",
      "Processed Julie_Marie_Berman: Train=20, Test=5\n",
      "Processed Channing_Tatum: Train=20, Test=5\n",
      "Processed David_Boreanaz: Train=20, Test=5\n",
      "Processed Matthew_Lillard: Train=20, Test=5\n",
      "Processed Tia_Carrere: Train=20, Test=5\n",
      "Processed Tamala_Jones: Train=20, Test=5\n",
      "Processed Kim_Delaney: Train=20, Test=5\n",
      "Processed Marilu_Henner: Train=20, Test=5\n",
      "Processed Kimberlin_Brown: Train=20, Test=5\n",
      "Processed Kerr_Smith: Train=20, Test=5\n",
      "Processed Chris_Noth: Train=20, Test=5\n",
      "Processed Pamela_Sue_Martin: Train=20, Test=5\n",
      "Processed Sharon_Gless: Train=20, Test=5\n",
      "Processed Owen_Wilson: Train=20, Test=5\n",
      "Processed James_McAvoy: Train=20, Test=5\n",
      "Processed Victoria_Justice: Train=20, Test=5\n",
      "Processed Clint_Eastwood: Train=20, Test=5\n",
      "Processed Ryan_Gosling: Train=20, Test=5\n",
      "Processed Joanna_Kerns: Train=20, Test=5\n",
      "Processed Sarah_Drew: Train=20, Test=5\n",
      "Processed Julia_Louis-Dreyfus: Train=20, Test=5\n",
      "Processed Ryan_Phillippe: Train=20, Test=5\n",
      "Processed Kathy_Baker: Train=20, Test=5\n",
      "Processed Jonathan_Rhys_Meyers: Train=20, Test=5\n",
      "Processed Samuel_L._Jackson: Train=20, Test=5\n",
      "Processed Yasmine_Bleeth: Train=20, Test=5\n",
      "Processed Vanessa_Marcil: Train=20, Test=5\n",
      "Processed Peggy_Lipton: Train=20, Test=5\n",
      "Processed Amy_Davidson: Train=20, Test=5\n",
      "Processed Bill_Cosby: Train=20, Test=5\n",
      "Processed Shelley_Hennig: Train=20, Test=5\n",
      "Processed Ian_McKellen: Train=20, Test=5\n",
      "Processed January_Jones: Train=20, Test=5\n",
      "Processed Ellen_DeGeneres: Train=20, Test=5\n",
      "Processed Cheryl_Ladd: Train=20, Test=5\n",
      "Processed Kristen_Johnston: Train=20, Test=5\n",
      "Processed Lesley-Anne_Down: Train=20, Test=5\n",
      "Processed Andrea_Bogart: Train=20, Test=5\n",
      "Processed Barbara_Carrera: Train=20, Test=5\n",
      "Processed Jimmy_Fallon: Train=20, Test=5\n",
      "Processed Jean-Claude_Van_Damme: Train=20, Test=5\n",
      "Processed Debi_Mazar: Train=20, Test=5\n",
      "Processed Portia_de_Rossi: Train=20, Test=5\n",
      "Processed Robert_Knepper: Train=20, Test=5\n",
      "Processed Karl_Urban: Train=20, Test=5\n",
      "Processed Matt_Czuchry: Train=20, Test=5\n",
      "Processed Melissa_Archer: Train=20, Test=5\n",
      "Processed Summer_Glau: Train=20, Test=5\n",
      "Processed Ashley_Benson: Train=20, Test=5\n",
      "Processed Jerry_Seinfeld: Train=20, Test=5\n",
      "Processed S._Epatha_Merkerson: Train=20, Test=5\n",
      "Processed America_Ferrera: Train=20, Test=5\n",
      "Processed Matthew_Broderick: Train=20, Test=5\n",
      "Processed Liev_Schreiber: Train=20, Test=5\n",
      "Processed James_Brolin: Train=20, Test=5\n",
      "Processed Joaquin_Phoenix: Train=20, Test=5\n",
      "Processed David_Schwimmer: Train=20, Test=5\n",
      "Processed Candice_Bergen: Train=20, Test=5\n",
      "Processed Ellen_Greene: Train=20, Test=5\n",
      "Processed Laurie_Metcalf: Train=20, Test=5\n",
      "Processed Kiefer_Sutherland: Train=20, Test=5\n",
      "Processed Rachel_Griffiths: Train=20, Test=5\n",
      "Processed Kevin_McKidd: Train=20, Test=5\n",
      "Processed Casey_Affleck: Train=20, Test=5\n",
      "Processed Bonnie_Franklin: Train=20, Test=5\n",
      "Processed Matt_Long: Train=20, Test=5\n",
      "Processed Rebecca_Herbst: Train=20, Test=5\n",
      "Processed Jane_Curtin: Train=20, Test=5\n",
      "Processed Matthew_Perry: Train=20, Test=5\n",
      "Processed Allison_Janney: Train=20, Test=5\n",
      "Processed Colin_Farrell: Train=20, Test=5\n",
      "Processed Mel_Gibson: Train=20, Test=5\n",
      "Processed Dominic_Monaghan: Train=20, Test=5\n",
      "Processed Staci_Keanan: Train=20, Test=5\n",
      "Processed Katrina_Bowden: Train=20, Test=5\n",
      "Processed Nicolas_Cage: Train=20, Test=5\n",
      "Processed Jonathan_Sadowski: Train=20, Test=5\n",
      "Processed Matt_Damon: Train=20, Test=5\n",
      "Processed Dana_Delany: Train=20, Test=5\n",
      "Processed Christopher_Reeve: Train=20, Test=5\n",
      "Processed Julianna_Margulies: Train=20, Test=5\n",
      "Processed Florencia_Lozano: Train=20, Test=5\n",
      "Processed Jackee_Harry: Train=20, Test=5\n",
      "Processed Matthew_Gray_Gubler: Train=20, Test=5\n",
      "Processed Angell_Conwell: Train=20, Test=5\n",
      "Processed Tracey_Gold: Train=20, Test=5\n",
      "Processed Al_Pacino: Train=20, Test=5\n",
      "Processed Chris_Kattan: Train=20, Test=5\n",
      "Skipping Adrianne_León, not enough images.\n",
      "Processed Joe_Pantoliano: Train=20, Test=5\n",
      "Processed Farah_Fath: Train=20, Test=5\n",
      "Processed Bill_Hader: Train=20, Test=5\n",
      "Processed Dustin_Hoffman: Train=20, Test=5\n",
      "Processed Melissa_Fumero: Train=20, Test=5\n",
      "Processed Carolyn_Hennesy: Train=20, Test=5\n",
      "Processed Patricia_Arquette: Train=20, Test=5\n",
      "Processed Orlando_Bloom: Train=20, Test=5\n",
      "Processed Lacey_Chabert: Train=20, Test=5\n",
      "Processed Robert_Patrick: Train=20, Test=5\n",
      "Processed Geena_Davis: Train=20, Test=5\n",
      "Processed Ray_Stevenson: Train=20, Test=5\n",
      "Processed George_Lopez: Train=20, Test=5\n",
      "Processed Morena_Baccarin: Train=20, Test=5\n",
      "Processed John_Cusack: Train=20, Test=5\n",
      "Processed Jude_Law: Train=20, Test=5\n",
      "Processed Eliza_Coupe: Train=20, Test=5\n",
      "Processed Patricia_Kalember: Train=20, Test=5\n",
      "Processed Susan_Dey: Train=20, Test=5\n",
      "Processed Lauren_Holly: Train=20, Test=5\n",
      "Processed Scott_Patterson: Train=20, Test=5\n",
      "Processed Luke_Wilson: Train=20, Test=5\n",
      "Processed Adrienne_Frantz: Train=20, Test=5\n",
      "Processed Christine_Lakin: Train=20, Test=5\n",
      "Processed Dean_Cain: Train=20, Test=5\n",
      "Processed Marcia_Cross: Train=20, Test=5\n",
      "Processed Carla_Gallo: Train=20, Test=5\n",
      "Processed Chris_Evans: Train=20, Test=5\n",
      "Processed Alec_Baldwin: Train=20, Test=5\n",
      "Processed Jackie_Chan: Train=20, Test=5\n",
      "Processed Richard_Madden: Train=20, Test=5\n",
      "Processed Richard_E._Grant: Train=20, Test=5\n",
      "Processed Omid_Djalili: Train=20, Test=5\n",
      "Processed Laura_Leighton: Train=20, Test=5\n",
      "Processed John_Krasinski: Train=20, Test=5\n",
      "Processed Kevin_Connolly: Train=20, Test=5\n",
      "Processed Jim_Carrey: Train=20, Test=5\n",
      "Processed Ken_Watanabe: Train=20, Test=5\n",
      "Processed Tatyana_M._Ali: Train=20, Test=5\n",
      "Processed Eliza_Dushku: Train=20, Test=5\n",
      "Processed Peter_Sarsgaard: Train=20, Test=5\n",
      "Processed Kristin_Chenoweth: Train=20, Test=5\n",
      "Processed Christopher_Lloyd: Train=20, Test=5\n",
      "Processed Dermot_Mulroney: Train=20, Test=5\n",
      "Processed Sasha_Alexander: Train=20, Test=5\n",
      "Processed Michael_Vartan: Train=20, Test=5\n",
      "Processed Robin_Williams: Train=20, Test=5\n",
      "Processed Roseanne_Barr: Train=20, Test=5\n",
      "Processed Brad_Pitt: Train=20, Test=5\n",
      "Processed Matt_Dillon: Train=20, Test=5\n",
      "Processed Jon_Voight: Train=20, Test=5\n",
      "Processed Natalie_Martinez: Train=20, Test=5\n",
      "Processed Leonardo_DiCaprio: Train=20, Test=5\n",
      "Processed Sherilyn_Fenn: Train=20, Test=5\n",
      "Processed Selena_Gomez: Train=20, Test=5\n",
      "Processed Julie_Bowen: Train=20, Test=5\n",
      "Processed Portia_Doubleday: Train=20, Test=5\n",
      "Processed Jamie_Lee_Curtis: Train=20, Test=5\n",
      "Processed Jared_Padalecki: Train=20, Test=5\n",
      "Processed Alan_Alda: Train=20, Test=5\n",
      "Processed Veronica_Hamel: Train=20, Test=5\n",
      "Processed Josh_Brolin: Train=20, Test=5\n",
      "Processed Clive_Owen: Train=20, Test=5\n",
      "Processed Didi_Conn: Train=20, Test=5\n",
      "Processed Danny_Masterson: Train=20, Test=5\n",
      "Processed Dwayne_Johnson: Train=20, Test=5\n",
      "Processed Anthony_Stewart_Head: Train=20, Test=5\n",
      "Processed Jon_Hamm: Train=20, Test=5\n",
      "Processed Aisha_Hinds: Train=20, Test=5\n",
      "Processed Kaley_Cuoco: Train=20, Test=5\n",
      "Processed Ioan_Gruffudd: Train=20, Test=5\n",
      "Processed Milo_Ventimiglia: Train=20, Test=5\n",
      "Processed Norman_Reedus: Train=20, Test=5\n",
      "Processed Lara_Flynn_Boyle: Train=20, Test=5\n",
      "Processed Arnold_Schwarzenegger: Train=20, Test=5\n",
      "Processed Justine_Bateman: Train=20, Test=5\n",
      "Processed Robert_Redford: Train=20, Test=5\n",
      "Processed Rue_McClanahan: Train=20, Test=5\n",
      "Processed Hector_Elizondo: Train=20, Test=5\n",
      "Processed J.K._Simmons: Train=20, Test=5\n",
      "Processed Chris_Rock: Train=20, Test=5\n",
      "Processed Adrienne_Barbeau: Train=20, Test=5\n",
      "Processed Jake_Gyllenhaal: Train=20, Test=5\n",
      "Processed Audrey_Landers: Train=20, Test=5\n",
      "Processed Jane_Krakowski: Train=20, Test=5\n",
      "Processed Andrea_Anders: Train=20, Test=5\n",
      "Processed Christian_Slater: Train=20, Test=5\n",
      "✅ Dataset organized successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define paths\n",
    "base_folders = [\"dataset/actor_faces\", \"dataset/actress_faces\"]\n",
    "train_folder = \"dataset/stagging/sampleset\"\n",
    "test_folder = \"dataset/stagging/testingset\"\n",
    "\n",
    "# Function to clear and recreate a folder\n",
    "def reset_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)  # Delete everything inside\n",
    "    os.makedirs(folder_path)  # Recreate the empty folder\n",
    "\n",
    "# Reset train and test folders\n",
    "reset_folder(train_folder)\n",
    "reset_folder(test_folder)\n",
    "# Collect all person folders from both `actor_faces` and `actress_faces`\n",
    "all_persons = []\n",
    "for base_folder in base_folders:\n",
    "    if os.path.exists(base_folder):  # Ensure the folder exists before listing\n",
    "        persons = [os.path.join(base_folder, p) for p in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, p))]\n",
    "        all_persons.extend(persons)  # Add full paths\n",
    "\n",
    "#print(all_persons)\n",
    "# Randomly select up to 200 persons\n",
    "selected_persons = random.sample(all_persons, min(200, len(all_persons)))\n",
    "print(f\"Selected {len(selected_persons)} persons.\")\n",
    "\n",
    "# Process each selected person\n",
    "for person_path in selected_persons:\n",
    "    person_name = os.path.basename(person_path)  # Extract only folder name\n",
    "\n",
    "    images = [img for img in os.listdir(person_path) if img.endswith((\".jpeg\", \".jpg\", \".png\"))]\n",
    "\n",
    "    if len(images) < 20:  # Skip if not enough images\n",
    "        print(f\"Skipping {person_name}, not enough images.\")\n",
    "        continue\n",
    "\n",
    "    # Shuffle and select max 25 images\n",
    "    random.shuffle(images)\n",
    "    selected_images = images[:25]\n",
    "\n",
    "    # Split into train (20) and test (5)\n",
    "    train_images = selected_images[:20]\n",
    "    test_images = selected_images[20:]\n",
    "\n",
    "    # Create person folders in train and test\n",
    "    train_person_path = os.path.join(train_folder, person_name)\n",
    "    test_person_path = os.path.join(test_folder, person_name)\n",
    "    os.makedirs(train_person_path, exist_ok=True)\n",
    "    os.makedirs(test_person_path, exist_ok=True)\n",
    "\n",
    "    # Move images\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(person_path, img), os.path.join(train_person_path, img))\n",
    "\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(person_path, img), os.path.join(test_person_path, img))\n",
    "\n",
    "    print(f\"Processed {person_name}: Train={len(train_images)}, Test={len(test_images)}\")\n",
    "\n",
    "print(\"✅ Dataset organized successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Process Image with MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Najwan\\AppData\\Local\\Temp\\ipykernel_21972\\1042745916.py:2: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_mtcnn(detector,dirpath, dirdest):\n",
    "    \n",
    "    imagePaths = sorted(list(paths.list_images(dirpath)))\n",
    "    for imagePath in tqdm(imagePaths):\n",
    "        #path_split = imagePath.split(os.sep)\n",
    "        path_split=Path(imagePath).parts\n",
    "        name_person = path_split[-2]\n",
    "        fn = path_split[-1].split('.')\n",
    "        filename, fileformat = fn[0], fn[1]\n",
    "\n",
    "        os.makedirs(dirdest, exist_ok=True)\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(imagePath), cv2.COLOR_BGR2RGB)\n",
    "        result = detector.detect_faces(image)\n",
    "        print(f\"Processing: {imagePath}, Faces detected: {len(result)}\")\n",
    "\n",
    "        for i in range(len(result)):\n",
    "            bounding_box = result[i]['box']\n",
    "            keypoints = result[i]['keypoints']\n",
    "\n",
    "            bounding_box[0] = max(0, bounding_box[0])\n",
    "            bounding_box[1] = max(0, bounding_box[1])\n",
    "\n",
    "            person_dir = os.path.join(dirdest, name_person)\n",
    "            os.makedirs(person_dir, exist_ok=True)\n",
    "            path_save = os.path.join(person_dir, f\"{filename}_{i}.{fileformat}\")\n",
    "            print(path_save)\n",
    "            img = image[bounding_box[1]:bounding_box[1] + bounding_box[3],\n",
    "                    bounding_box[0]:bounding_box[0] + bounding_box[2]]\n",
    "\n",
    "            cv2.imwrite(path_save, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "    print(\"Face detection and cropping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [00:00<00:05,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: dataset/stagging/sampleset\\Hugh Jackman\\Hugh Jackman_1.jpg, Faces detected: 1\n",
      "dataset/mtcnn_faces/sampleset\\Hugh Jackman\\Hugh Jackman_1_0.jpg\n",
      "Processing: dataset/stagging/sampleset\\Hugh Jackman\\Hugh Jackman_10.jpg, Faces detected: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m dirpaths\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/stagging/sampleset\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/stagging/testingset\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dirpath \u001b[38;5;129;01min\u001b[39;00m dirpaths:\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mprocessed_mtcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMTCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdirpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdirdest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdirpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstagging\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmtcnn_faces\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 13\u001b[0m, in \u001b[0;36mprocessed_mtcnn\u001b[1;34m(detector, dirpath, dirdest)\u001b[0m\n\u001b[0;32m      9\u001b[0m filename, fileformat \u001b[38;5;241m=\u001b[39m fn[\u001b[38;5;241m0\u001b[39m], fn[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     11\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(dirdest, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 13\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagePath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m result \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mdetect_faces(image)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimagePath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Faces detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "dirpaths=['dataset/stagging/sampleset','dataset/stagging/testingset']\n",
    "\n",
    "for dirpath in dirpaths:\n",
    "    processed_mtcnn(detector=MTCNN(),dirpath=dirpath,dirdest=dirpath.replace(\"stagging\",\"mtcnn_faces\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Face Verification with DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'dataset/mtcnn_faces/sampleset/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m test_path\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset/mtcnn_faces/testingset\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Example: Compare images\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img1 \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m img2 \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(test_path):\n\u001b[0;32m     12\u001b[0m         result \u001b[38;5;241m=\u001b[39m DeepFace\u001b[38;5;241m.\u001b[39mverify(\n\u001b[0;32m     13\u001b[0m             img1_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_path, img1),\n\u001b[0;32m     14\u001b[0m             img2_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(test_path, img2),\n\u001b[0;32m     15\u001b[0m             model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVGG-Face\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m             distance_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m         )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'dataset/mtcnn_faces/sampleset/'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = []  # 1 for same person, 0 for different person\n",
    "y_pred = []  # 1 if verified, 0 if not verified\n",
    "\n",
    "train_path='dataset/mtcnn_faces/sampleset/'\n",
    "test_path= 'dataset/mtcnn_faces/testingset'\n",
    "\n",
    "# Example: Compare images\n",
    "for img1 in os.listdir(train_path):\n",
    "    for img2 in os.listdir(test_path):\n",
    "        result = DeepFace.verify(\n",
    "            img1_path=os.path.join(train_path, img1),\n",
    "            img2_path=os.path.join(test_path, img2),\n",
    "            model_name=\"VGG-Face\",\n",
    "            distance_metric=\"cosine\"\n",
    "        )\n",
    "\n",
    "        y_true.append(1 if \"personA\" in img1 and \"personA\" in img2 else 0)\n",
    "        y_pred.append(1 if result[\"verified\"] else 0)\n",
    "\n",
    "# Calculate Metrics\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
