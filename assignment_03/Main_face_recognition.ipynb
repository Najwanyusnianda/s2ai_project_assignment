{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Comparison of Face Recognition Models (Assignment 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nama:Najwan Yusnianda\n",
    "NIM: 2408207010029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from imutils import paths\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from deepface import DeepFace\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of row (images) : 106865\n"
     ]
    }
   ],
   "source": [
    "## import metadata\n",
    "facescrub_df_actor = pd.read_csv('faceScrub/facescrub_actors.txt',delimiter='\\t',header=None)\n",
    "facescrub_df_actress = pd.read_csv('faceScrub/facescrub_actresses.txt',delimiter='\\t',header=None)\n",
    "\n",
    "#combine dataframe\n",
    "facescrub_df=pd.concat([facescrub_df_actor,facescrub_df_actress],axis=0)\n",
    "\n",
    "print(f\"number of row (images) : {len(facescrub_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique faces (people): 531\n",
      "            name  count\n",
      "0  Aaron Eckhart    231\n",
      "1     Adam Brody    200\n",
      "2     Adam McKay    108\n",
      "3   Adam Sandler    208\n",
      "4  Adrianne Le√≥n     62\n"
     ]
    }
   ],
   "source": [
    "# Group by the first column (name) and count the occurrences\n",
    "name_count_df = facescrub_df.groupby(facescrub_df.columns[0]).size().reset_index(name='count')\n",
    "\n",
    "# Rename the columns for clarity\n",
    "name_count_df.columns = ['name', 'count']\n",
    "name_count_df.head()\n",
    "# Display the new dataframe\n",
    "#name_count_df=name_count_df.sort_values(by='count', ascending=False)\n",
    "print(f\"number of unique faces (people): {len(name_count_df)}\")\n",
    "print(name_count_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_detect_faces(url, filename):\n",
    "    detector = MTCNN()\n",
    "    \n",
    "    try:\n",
    "\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Convert to numpy array \n",
    "        image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
    "        image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "    \n",
    "        #check if image\n",
    "        if image is None:\n",
    "            return 0\n",
    "\n",
    "        # Detect faces in the image\n",
    "        result = detector.detect_faces(image)\n",
    "        if not len(result) ==1:\n",
    "            #print(f\"no face detected in {filename} number of face detected: {len(result)}\")\n",
    "            return 0\n",
    "            \n",
    "        # Only save the image if faces detected\n",
    "        cv2.imwrite(filename, image)\n",
    "        return 1\n",
    "        \n",
    "    except (requests.exceptions.RequestException, cv2.error) as e:\n",
    "        #remove image if not contain face\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                os.remove(filename)\n",
    "            except OSError:\n",
    "                pass\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        # Catch any other unexpected errors\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                os.remove(filename)\n",
    "            except OSError:\n",
    "                pass\n",
    "        return 0\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def get_image_sample(num_person,ntrain_person,ntest_person,nval_person,facescrub_df):\n",
    "    current_num_person = 0\n",
    "\n",
    "    list_person = []\n",
    "\n",
    "    while current_num_person<num_person:\n",
    "        current_ntrain_person = 0\n",
    "        current_ntest_person = 0\n",
    "        current_nval_person = 0\n",
    "        ##generate angka random sebagai index dari dataset\n",
    "        random_num = np.random.randint(0, facescrub_df.shape[0])\n",
    "        ##ambil nama orang dari dataset\n",
    "        \n",
    "        current_person=facescrub_df.iloc[random_num,0]\n",
    "        \n",
    "        if current_person in list_person:\n",
    "            continue\n",
    "        else:\n",
    "        ##buat dataset dengan data orang tersebut\n",
    "            df_persons=facescrub_df[facescrub_df[0]==current_person]\n",
    "            \n",
    "            train_path = 'dataset/stagging/sampleset/'+current_person\n",
    "            val_path = 'dataset/stagging/validationset/'+current_person\n",
    "            test_path = 'dataset/stagging/testingset/'+current_person\n",
    "            ##buat folder untuk orang tersebut\n",
    "            if not os.path.exists(train_path):\n",
    "                \n",
    "                os.makedirs(train_path)\n",
    "            if not os.path.exists(test_path):\n",
    "                os.makedirs(test_path)\n",
    "\n",
    "            len_train = print(f\"dwonload image person={current_person} num_image={df_persons.shape[0]}\")\n",
    "            \n",
    "            \n",
    "            list_index_person=[]\n",
    "            while current_ntrain_person<ntrain_person:\n",
    "                    #get random index\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)\n",
    "                    ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_and_detect_faces(url, train_path+'/'+current_person+'_'+str(current_ntrain_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_ntrain_person+=1\n",
    "                        if current_ntrain_person % 10 == 0:\n",
    "                            print(f\"sample_person set image added for {current_person}: {current_ntrain_person}\")\n",
    "            while current_nval_person<nval_person:\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)    \n",
    "                     ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_and_detect_faces(url, val_path+'/'+current_person+'_'+str(current_nval_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_nval_person+=1\n",
    "                        if current_nval_person % 5 == 0:\n",
    "                            print(f\"val_person set image added for {current_person}: {current_nval_person}\")\n",
    "            while current_ntest_person<ntest_person:\n",
    "                i = np.random.randint(0, df_persons.shape[0])\n",
    "                if i in list_index_person:\n",
    "                    continue\n",
    "                else:\n",
    "                    list_index_person.append(i)    \n",
    "                     ##ambil url gambar\n",
    "                    url = df_persons.iloc[i,3]\n",
    "                    ##download gambar\n",
    "                    isdownload=download_and_detect_faces(url, test_path+'/'+current_person+'_'+str(current_ntest_person+1)+'.jpg')\n",
    "                    if isdownload==1:\n",
    "                        current_ntest_person+=1\n",
    "                        if current_ntest_person % 5 == 0:\n",
    "                            print(f\"test_person set image added fro {current_person}: {current_ntest_person}\")\n",
    "            list_person.append(current_person)\n",
    "            current_num_person+=1\n",
    "            print(f\"=== [{current_num_person}/{num_person}] Person added: {current_person} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dwonload image person=Robert Di Niro num_image=200\n",
      "sample_person set image added for Robert Di Niro: 10\n",
      "sample_person set image added for Robert Di Niro: 20\n",
      "val_person set image added for Robert Di Niro: 5\n",
      "test_person set image added fro Robert Di Niro: 5\n",
      "=== [1/200] Person added: Robert Di Niro ===\n",
      "dwonload image person=Wendie Malick num_image=219\n",
      "sample_person set image added for Wendie Malick: 10\n",
      "sample_person set image added for Wendie Malick: 20\n",
      "val_person set image added for Wendie Malick: 5\n",
      "test_person set image added fro Wendie Malick: 5\n",
      "=== [2/200] Person added: Wendie Malick ===\n",
      "dwonload image person=Jennie Garth num_image=245\n",
      "sample_person set image added for Jennie Garth: 10\n",
      "sample_person set image added for Jennie Garth: 20\n",
      "val_person set image added for Jennie Garth: 5\n",
      "test_person set image added fro Jennie Garth: 5\n",
      "=== [3/200] Person added: Jennie Garth ===\n",
      "dwonload image person=Linda Gray num_image=226\n",
      "sample_person set image added for Linda Gray: 10\n",
      "sample_person set image added for Linda Gray: 20\n",
      "val_person set image added for Linda Gray: 5\n",
      "test_person set image added fro Linda Gray: 5\n",
      "=== [4/200] Person added: Linda Gray ===\n",
      "dwonload image person=Cary Elwes num_image=230\n",
      "sample_person set image added for Cary Elwes: 10\n",
      "sample_person set image added for Cary Elwes: 20\n",
      "val_person set image added for Cary Elwes: 5\n"
     ]
    }
   ],
   "source": [
    "##run function to get image sample\n",
    "get_image_sample(num_person=200,ntrain_person=20,ntest_person=5,nval_person=5,facescrub_df=facescrub_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Organize folder(optional if all faces allready download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 200 persons.\n",
      "Processed Kassie_DePaiva: Train=20, Test=5\n",
      "Processed Bradley_Cooper: Train=20, Test=5\n",
      "Processed Cam_Gigandet: Train=20, Test=5\n",
      "Processed Audra_McDonald: Train=20, Test=5\n",
      "Processed Shannon_Kane: Train=20, Test=5\n",
      "Processed Crystal_Chappell: Train=20, Test=5\n",
      "Processed Jennette_McCurdy: Train=20, Test=5\n",
      "Processed John_Malkovich: Train=20, Test=5\n",
      "Processed Seth_Rogen: Train=20, Test=5\n",
      "Processed Kris_Kristofferson: Train=20, Test=5\n",
      "Processed John_Noble: Train=20, Test=5\n",
      "Processed Catherine_Bell: Train=20, Test=5\n",
      "Processed Sean_Bean: Train=20, Test=5\n",
      "Processed Alyssa_Milano: Train=20, Test=5\n",
      "Processed Jason_Behr: Train=20, Test=5\n",
      "Processed Martin_Sheen: Train=20, Test=5\n",
      "Processed Antonio_Banderas: Train=20, Test=5\n",
      "Processed Tempestt_Bledsoe: Train=20, Test=5\n",
      "Processed Ed_Harris: Train=20, Test=5\n",
      "Processed Valerie_Harper: Train=20, Test=5\n",
      "Processed Amaury_Nolasco: Train=20, Test=5\n",
      "Processed Oliver_Platt: Train=20, Test=5\n",
      "Processed Chyler_Leigh: Train=20, Test=5\n",
      "Processed Jensen_Ackles: Train=20, Test=5\n",
      "Processed Julie_Marie_Berman: Train=20, Test=5\n",
      "Processed Channing_Tatum: Train=20, Test=5\n",
      "Processed David_Boreanaz: Train=20, Test=5\n",
      "Processed Matthew_Lillard: Train=20, Test=5\n",
      "Processed Tia_Carrere: Train=20, Test=5\n",
      "Processed Tamala_Jones: Train=20, Test=5\n",
      "Processed Kim_Delaney: Train=20, Test=5\n",
      "Processed Marilu_Henner: Train=20, Test=5\n",
      "Processed Kimberlin_Brown: Train=20, Test=5\n",
      "Processed Kerr_Smith: Train=20, Test=5\n",
      "Processed Chris_Noth: Train=20, Test=5\n",
      "Processed Pamela_Sue_Martin: Train=20, Test=5\n",
      "Processed Sharon_Gless: Train=20, Test=5\n",
      "Processed Owen_Wilson: Train=20, Test=5\n",
      "Processed James_McAvoy: Train=20, Test=5\n",
      "Processed Victoria_Justice: Train=20, Test=5\n",
      "Processed Clint_Eastwood: Train=20, Test=5\n",
      "Processed Ryan_Gosling: Train=20, Test=5\n",
      "Processed Joanna_Kerns: Train=20, Test=5\n",
      "Processed Sarah_Drew: Train=20, Test=5\n",
      "Processed Julia_Louis-Dreyfus: Train=20, Test=5\n",
      "Processed Ryan_Phillippe: Train=20, Test=5\n",
      "Processed Kathy_Baker: Train=20, Test=5\n",
      "Processed Jonathan_Rhys_Meyers: Train=20, Test=5\n",
      "Processed Samuel_L._Jackson: Train=20, Test=5\n",
      "Processed Yasmine_Bleeth: Train=20, Test=5\n",
      "Processed Vanessa_Marcil: Train=20, Test=5\n",
      "Processed Peggy_Lipton: Train=20, Test=5\n",
      "Processed Amy_Davidson: Train=20, Test=5\n",
      "Processed Bill_Cosby: Train=20, Test=5\n",
      "Processed Shelley_Hennig: Train=20, Test=5\n",
      "Processed Ian_McKellen: Train=20, Test=5\n",
      "Processed January_Jones: Train=20, Test=5\n",
      "Processed Ellen_DeGeneres: Train=20, Test=5\n",
      "Processed Cheryl_Ladd: Train=20, Test=5\n",
      "Processed Kristen_Johnston: Train=20, Test=5\n",
      "Processed Lesley-Anne_Down: Train=20, Test=5\n",
      "Processed Andrea_Bogart: Train=20, Test=5\n",
      "Processed Barbara_Carrera: Train=20, Test=5\n",
      "Processed Jimmy_Fallon: Train=20, Test=5\n",
      "Processed Jean-Claude_Van_Damme: Train=20, Test=5\n",
      "Processed Debi_Mazar: Train=20, Test=5\n",
      "Processed Portia_de_Rossi: Train=20, Test=5\n",
      "Processed Robert_Knepper: Train=20, Test=5\n",
      "Processed Karl_Urban: Train=20, Test=5\n",
      "Processed Matt_Czuchry: Train=20, Test=5\n",
      "Processed Melissa_Archer: Train=20, Test=5\n",
      "Processed Summer_Glau: Train=20, Test=5\n",
      "Processed Ashley_Benson: Train=20, Test=5\n",
      "Processed Jerry_Seinfeld: Train=20, Test=5\n",
      "Processed S._Epatha_Merkerson: Train=20, Test=5\n",
      "Processed America_Ferrera: Train=20, Test=5\n",
      "Processed Matthew_Broderick: Train=20, Test=5\n",
      "Processed Liev_Schreiber: Train=20, Test=5\n",
      "Processed James_Brolin: Train=20, Test=5\n",
      "Processed Joaquin_Phoenix: Train=20, Test=5\n",
      "Processed David_Schwimmer: Train=20, Test=5\n",
      "Processed Candice_Bergen: Train=20, Test=5\n",
      "Processed Ellen_Greene: Train=20, Test=5\n",
      "Processed Laurie_Metcalf: Train=20, Test=5\n",
      "Processed Kiefer_Sutherland: Train=20, Test=5\n",
      "Processed Rachel_Griffiths: Train=20, Test=5\n",
      "Processed Kevin_McKidd: Train=20, Test=5\n",
      "Processed Casey_Affleck: Train=20, Test=5\n",
      "Processed Bonnie_Franklin: Train=20, Test=5\n",
      "Processed Matt_Long: Train=20, Test=5\n",
      "Processed Rebecca_Herbst: Train=20, Test=5\n",
      "Processed Jane_Curtin: Train=20, Test=5\n",
      "Processed Matthew_Perry: Train=20, Test=5\n",
      "Processed Allison_Janney: Train=20, Test=5\n",
      "Processed Colin_Farrell: Train=20, Test=5\n",
      "Processed Mel_Gibson: Train=20, Test=5\n",
      "Processed Dominic_Monaghan: Train=20, Test=5\n",
      "Processed Staci_Keanan: Train=20, Test=5\n",
      "Processed Katrina_Bowden: Train=20, Test=5\n",
      "Processed Nicolas_Cage: Train=20, Test=5\n",
      "Processed Jonathan_Sadowski: Train=20, Test=5\n",
      "Processed Matt_Damon: Train=20, Test=5\n",
      "Processed Dana_Delany: Train=20, Test=5\n",
      "Processed Christopher_Reeve: Train=20, Test=5\n",
      "Processed Julianna_Margulies: Train=20, Test=5\n",
      "Processed Florencia_Lozano: Train=20, Test=5\n",
      "Processed Jackee_Harry: Train=20, Test=5\n",
      "Processed Matthew_Gray_Gubler: Train=20, Test=5\n",
      "Processed Angell_Conwell: Train=20, Test=5\n",
      "Processed Tracey_Gold: Train=20, Test=5\n",
      "Processed Al_Pacino: Train=20, Test=5\n",
      "Processed Chris_Kattan: Train=20, Test=5\n",
      "Skipping Adrianne_LeoÃÅn, not enough images.\n",
      "Processed Joe_Pantoliano: Train=20, Test=5\n",
      "Processed Farah_Fath: Train=20, Test=5\n",
      "Processed Bill_Hader: Train=20, Test=5\n",
      "Processed Dustin_Hoffman: Train=20, Test=5\n",
      "Processed Melissa_Fumero: Train=20, Test=5\n",
      "Processed Carolyn_Hennesy: Train=20, Test=5\n",
      "Processed Patricia_Arquette: Train=20, Test=5\n",
      "Processed Orlando_Bloom: Train=20, Test=5\n",
      "Processed Lacey_Chabert: Train=20, Test=5\n",
      "Processed Robert_Patrick: Train=20, Test=5\n",
      "Processed Geena_Davis: Train=20, Test=5\n",
      "Processed Ray_Stevenson: Train=20, Test=5\n",
      "Processed George_Lopez: Train=20, Test=5\n",
      "Processed Morena_Baccarin: Train=20, Test=5\n",
      "Processed John_Cusack: Train=20, Test=5\n",
      "Processed Jude_Law: Train=20, Test=5\n",
      "Processed Eliza_Coupe: Train=20, Test=5\n",
      "Processed Patricia_Kalember: Train=20, Test=5\n",
      "Processed Susan_Dey: Train=20, Test=5\n",
      "Processed Lauren_Holly: Train=20, Test=5\n",
      "Processed Scott_Patterson: Train=20, Test=5\n",
      "Processed Luke_Wilson: Train=20, Test=5\n",
      "Processed Adrienne_Frantz: Train=20, Test=5\n",
      "Processed Christine_Lakin: Train=20, Test=5\n",
      "Processed Dean_Cain: Train=20, Test=5\n",
      "Processed Marcia_Cross: Train=20, Test=5\n",
      "Processed Carla_Gallo: Train=20, Test=5\n",
      "Processed Chris_Evans: Train=20, Test=5\n",
      "Processed Alec_Baldwin: Train=20, Test=5\n",
      "Processed Jackie_Chan: Train=20, Test=5\n",
      "Processed Richard_Madden: Train=20, Test=5\n",
      "Processed Richard_E._Grant: Train=20, Test=5\n",
      "Processed Omid_Djalili: Train=20, Test=5\n",
      "Processed Laura_Leighton: Train=20, Test=5\n",
      "Processed John_Krasinski: Train=20, Test=5\n",
      "Processed Kevin_Connolly: Train=20, Test=5\n",
      "Processed Jim_Carrey: Train=20, Test=5\n",
      "Processed Ken_Watanabe: Train=20, Test=5\n",
      "Processed Tatyana_M._Ali: Train=20, Test=5\n",
      "Processed Eliza_Dushku: Train=20, Test=5\n",
      "Processed Peter_Sarsgaard: Train=20, Test=5\n",
      "Processed Kristin_Chenoweth: Train=20, Test=5\n",
      "Processed Christopher_Lloyd: Train=20, Test=5\n",
      "Processed Dermot_Mulroney: Train=20, Test=5\n",
      "Processed Sasha_Alexander: Train=20, Test=5\n",
      "Processed Michael_Vartan: Train=20, Test=5\n",
      "Processed Robin_Williams: Train=20, Test=5\n",
      "Processed Roseanne_Barr: Train=20, Test=5\n",
      "Processed Brad_Pitt: Train=20, Test=5\n",
      "Processed Matt_Dillon: Train=20, Test=5\n",
      "Processed Jon_Voight: Train=20, Test=5\n",
      "Processed Natalie_Martinez: Train=20, Test=5\n",
      "Processed Leonardo_DiCaprio: Train=20, Test=5\n",
      "Processed Sherilyn_Fenn: Train=20, Test=5\n",
      "Processed Selena_Gomez: Train=20, Test=5\n",
      "Processed Julie_Bowen: Train=20, Test=5\n",
      "Processed Portia_Doubleday: Train=20, Test=5\n",
      "Processed Jamie_Lee_Curtis: Train=20, Test=5\n",
      "Processed Jared_Padalecki: Train=20, Test=5\n",
      "Processed Alan_Alda: Train=20, Test=5\n",
      "Processed Veronica_Hamel: Train=20, Test=5\n",
      "Processed Josh_Brolin: Train=20, Test=5\n",
      "Processed Clive_Owen: Train=20, Test=5\n",
      "Processed Didi_Conn: Train=20, Test=5\n",
      "Processed Danny_Masterson: Train=20, Test=5\n",
      "Processed Dwayne_Johnson: Train=20, Test=5\n",
      "Processed Anthony_Stewart_Head: Train=20, Test=5\n",
      "Processed Jon_Hamm: Train=20, Test=5\n",
      "Processed Aisha_Hinds: Train=20, Test=5\n",
      "Processed Kaley_Cuoco: Train=20, Test=5\n",
      "Processed Ioan_Gruffudd: Train=20, Test=5\n",
      "Processed Milo_Ventimiglia: Train=20, Test=5\n",
      "Processed Norman_Reedus: Train=20, Test=5\n",
      "Processed Lara_Flynn_Boyle: Train=20, Test=5\n",
      "Processed Arnold_Schwarzenegger: Train=20, Test=5\n",
      "Processed Justine_Bateman: Train=20, Test=5\n",
      "Processed Robert_Redford: Train=20, Test=5\n",
      "Processed Rue_McClanahan: Train=20, Test=5\n",
      "Processed Hector_Elizondo: Train=20, Test=5\n",
      "Processed J.K._Simmons: Train=20, Test=5\n",
      "Processed Chris_Rock: Train=20, Test=5\n",
      "Processed Adrienne_Barbeau: Train=20, Test=5\n",
      "Processed Jake_Gyllenhaal: Train=20, Test=5\n",
      "Processed Audrey_Landers: Train=20, Test=5\n",
      "Processed Jane_Krakowski: Train=20, Test=5\n",
      "Processed Andrea_Anders: Train=20, Test=5\n",
      "Processed Christian_Slater: Train=20, Test=5\n",
      "‚úÖ Dataset organized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "\n",
    "# Initialize MTCNN detector\n",
    "detector = MTCNN()\n",
    "\n",
    "# Define paths\n",
    "base_folders = [\"dataset/actors\", \"dataset/actress\"]\n",
    "train_folder = \"dataset/stagging/sampleset\"\n",
    "validation_folder = \"dataset/stagging/validationset\"\n",
    "test_folder = \"dataset/stagging/testingset\"\n",
    "\n",
    "# Function to reset a folder\n",
    "def reset_folder(folder_path):\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "# Reset dataset folders\n",
    "reset_folder(train_folder)\n",
    "reset_folder(validation_folder)\n",
    "reset_folder(test_folder)\n",
    "\n",
    "# Collect all person folders\n",
    "all_persons = []\n",
    "for base_folder in base_folders:\n",
    "    if os.path.exists(base_folder):\n",
    "        persons = [\n",
    "            os.path.join(base_folder, p) for p in os.listdir(base_folder)\n",
    "            if os.path.isdir(os.path.join(base_folder, p))\n",
    "        ]\n",
    "        all_persons.extend(persons)\n",
    "print(f\"Found {len(all_persons)} persons.\")\n",
    "\n",
    "# Randomly select up to 200 persons\n",
    "selected_persons = random.sample(all_persons, min(200, len(all_persons)))\n",
    "print(f\"Selected {len(selected_persons)} persons.\")\n",
    "\n",
    "def is_valid_face(image_path):\n",
    "    \"\"\"Check if an image contains exactly one detectable face.\"\"\"\n",
    "    try:\n",
    "        image = cv2.imread(image_path)  # Read the image\n",
    "        result = detector.detect_faces(image)  # Detect faces\n",
    "\n",
    "        if len(result) == 1:  # Keep only images with exactly 1 face\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "# Process each selected person\n",
    "for person_path in selected_persons:\n",
    "    person_name = os.path.basename(person_path)\n",
    "    print(f\"Processing {person_name}...\")\n",
    "\n",
    "    images = [img for img in os.listdir(person_path) if img.endswith((\".jpeg\", \".jpg\", \".png\"))]\n",
    "\n",
    "    # Shuffle images\n",
    "    random.shuffle(images)\n",
    "\n",
    "    # Filter images with exactly one detected face\n",
    "    valid_images = [img for img in images if is_valid_face(os.path.join(person_path, img))]\n",
    "\n",
    "    # Skip if fewer than 20 valid images\n",
    "    if len(valid_images) < 20:\n",
    "        print(f\"‚ö†Ô∏è Skipping {person_name}, not enough valid face images.\")\n",
    "        continue\n",
    "\n",
    "    # Select max 25 valid images\n",
    "    selected_images = valid_images[:30]\n",
    "    train_images = selected_images[:20]  # 15 for training\n",
    "    validation_images = selected_images[20:25]  # 5 for validation\n",
    "    test_images = selected_images[25:]  # 5 for testing\n",
    "\n",
    "    # Create person-specific directories\n",
    "    train_person_path = os.path.join(train_folder, person_name)\n",
    "    validation_person_path = os.path.join(validation_folder, person_name)\n",
    "    test_person_path = os.path.join(test_folder, person_name)\n",
    "\n",
    "    os.makedirs(train_person_path, exist_ok=True)\n",
    "    os.makedirs(validation_person_path, exist_ok=True)\n",
    "    os.makedirs(test_person_path, exist_ok=True)\n",
    "\n",
    "    # Copy images to respective folders\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(person_path, img), os.path.join(train_person_path, img))\n",
    "\n",
    "    for img in validation_images:\n",
    "        shutil.copy(os.path.join(person_path, img), os.path.join(validation_person_path, img))\n",
    "\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(person_path, img), os.path.join(test_person_path, img))\n",
    "\n",
    "    print(f\"‚úÖ Processed {person_name}: Train={len(train_images)}, Validation={len(validation_images)}, Test={len(test_images)}\")\n",
    "\n",
    "print(\"üéâ Dataset successfully filtered and organized!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Process Image with MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Najwan\\AppData\\Local\\Temp\\ipykernel_21972\\1042745916.py:2: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed_mtcnn(detector,dirpath, dirdest):\n",
    "    \n",
    "    imagePaths = sorted(list(paths.list_images(dirpath)))\n",
    "    for imagePath in tqdm(imagePaths):\n",
    "        #path_split = imagePath.split(os.sep)\n",
    "        path_split=Path(imagePath).parts\n",
    "        name_person = path_split[-2]\n",
    "        fn = path_split[-1].split('.')\n",
    "        filename, fileformat = fn[0], fn[1]\n",
    "\n",
    "        os.makedirs(dirdest, exist_ok=True)\n",
    "\n",
    "        image = cv2.cvtColor(cv2.imread(imagePath), cv2.COLOR_BGR2RGB)\n",
    "        result = detector.detect_faces(image)\n",
    "        #print(f\"Processing: {imagePath}, Faces detected: {len(result)}\")\n",
    "\n",
    "        for i in range(len(result)):\n",
    "            bounding_box = result[i]['box']\n",
    "            keypoints = result[i]['keypoints']\n",
    "\n",
    "            bounding_box[0] = max(0, bounding_box[0])\n",
    "            bounding_box[1] = max(0, bounding_box[1])\n",
    "\n",
    "            person_dir = os.path.join(dirdest, name_person)\n",
    "            os.makedirs(person_dir, exist_ok=True)\n",
    "            path_save = os.path.join(person_dir, f\"{filename}_{i}.{fileformat}\")\n",
    "            print(path_save)\n",
    "            img = image[bounding_box[1]:bounding_box[1] + bounding_box[3],\n",
    "                    bounding_box[0]:bounding_box[0] + bounding_box[2]]\n",
    "\n",
    "            cv2.imwrite(path_save, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "    print(\"Face detection and cropping completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 2/100 [00:00<00:17,  5.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9044_4231_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9045_4232_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 4/100 [00:00<00:14,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9059_4240_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9065_4243_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|‚ñå         | 6/100 [00:00<00:14,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9082_4252_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9096_4256_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|‚ñã         | 7/100 [00:01<00:14,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9119_4271_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|‚ñâ         | 9/100 [00:01<00:14,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9124_4274_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9131_4278_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|‚ñà         | 11/100 [00:02<00:18,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9149_4286_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9154_4289_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|‚ñà‚ñé        | 13/100 [00:02<00:16,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9187_4306_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9198_4310_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|‚ñà‚ñå        | 15/100 [00:02<00:14,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9200_4312_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9213_4318_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 16/100 [00:02<00:15,  5.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9232_4327_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|‚ñà‚ñä        | 18/100 [00:03<00:15,  5.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9238_4329_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9280_4352_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 20/100 [00:03<00:12,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9300_4362_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Barbeau\\Adrienne_Barbeau_9341_4378_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|‚ñà‚ñà        | 21/100 [00:03<00:11,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58140_27673_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58149_27680_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|‚ñà‚ñà‚ñé       | 23/100 [00:04<00:12,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58157_27688_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58167_27697_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|‚ñà‚ñà‚ñå       | 25/100 [00:04<00:10,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58175_27703_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|‚ñà‚ñà‚ñã       | 27/100 [00:04<00:11,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58177_27704_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58185_27711_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 28/100 [00:04<00:12,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58192_27716_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 30/100 [00:05<00:12,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58200_27721_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58213_27729_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58218_27733_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 33/100 [00:05<00:10,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58242_27754_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58249_27760_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58259_27767_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 36/100 [00:06<00:09,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58280_27784_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58329_27821_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|‚ñà‚ñà‚ñà‚ñä      | 38/100 [00:06<00:08,  7.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58338_27829_0.png\n",
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58347_27835_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|‚ñà‚ñà‚ñà‚ñâ      | 39/100 [00:06<00:08,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58377_27858_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|‚ñà‚ñà‚ñà‚ñà      | 41/100 [00:06<00:09,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Adrienne_Frantz\\Adrienne_Frantz_58380_27861_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78813_35707_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 42/100 [00:07<00:12,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78815_35709_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 44/100 [00:07<00:12,  4.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78819_35712_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78831_35719_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 46/100 [00:07<00:09,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78833_35721_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78837_35723_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 47/100 [00:08<00:11,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78843_35726_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 48/100 [00:08<00:11,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78848_35727_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 50/100 [00:08<00:11,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78851_35729_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78853_35731_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 52/100 [00:09<00:10,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78858_35734_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78890_35746_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78894_35747_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78927_35758_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 57/100 [00:10<00:06,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78934_35761_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78952_35771_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78977_35776_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 59/100 [00:10<00:05,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_78995_35784_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_79041_35796_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 60/100 [00:10<00:05,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Aisha_Hinds\\Aisha_Hinds_79077_35803_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 61/100 [00:10<00:08,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1800_964_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 62/100 [00:11<00:09,  4.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1814_975_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 63/100 [00:11<00:09,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1844_999_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1852_1007_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 66/100 [00:12<00:06,  4.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1855_1008_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1856_1009_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 68/100 [00:12<00:05,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1859_1012_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1879_1027_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 69/100 [00:12<00:05,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1940_1062_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 70/100 [00:12<00:05,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1952_1070_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 71/100 [00:13<00:06,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1970_1076_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 72/100 [00:13<00:06,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_1992_1087_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 73/100 [00:14<00:10,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2015_1101_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 74/100 [00:14<00:11,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2034_1112_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 75/100 [00:15<00:10,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2049_1120_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 76/100 [00:15<00:10,  2.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2095_1139_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 77/100 [00:15<00:09,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2100_1141_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2111_1146_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 79/100 [00:16<00:07,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2121_1151_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 80/100 [00:16<00:06,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Al_Pacino\\Al_Pacino_2122_1152_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 82/100 [00:17<00:05,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2165_1180_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2192_1204_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 83/100 [00:17<00:05,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2206_1215_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 84/100 [00:17<00:04,  3.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2207_1216_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 85/100 [00:18<00:05,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2218_1222_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 86/100 [00:18<00:04,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2224_1228_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 87/100 [00:18<00:04,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2233_1235_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 89/100 [00:19<00:03,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2256_1251_0.jpeg\n",
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2259_1253_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 90/100 [00:19<00:03,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2297_1279_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 91/100 [00:20<00:02,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2308_1287_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 92/100 [00:20<00:02,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2321_1298_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 93/100 [00:20<00:02,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2323_1300_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 94/100 [00:21<00:02,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2352_1323_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 95/100 [00:21<00:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2385_1345_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 96/100 [00:21<00:01,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2389_1349_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 97/100 [00:22<00:01,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2396_1354_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 98/100 [00:22<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2442_1388_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 99/100 [00:23<00:00,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2451_1395_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:23<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/sampleset\\Alan_Alda\\Alan_Alda_2490_1420_0.jpeg\n",
      "Face detection and cropping completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|‚ñç         | 1/25 [00:00<00:04,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9127_4276_0.jpeg\n",
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9229_4326_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|‚ñà‚ñè        | 3/25 [00:00<00:06,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9267_4347_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|‚ñà‚ñå        | 4/25 [00:01<00:06,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9302_4363_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|‚ñà‚ñà‚ñç       | 6/25 [00:01<00:05,  3.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Barbeau\\Adrienne_Barbeau_9335_4376_0.jpeg\n",
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58205_27724_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|‚ñà‚ñà‚ñä       | 7/25 [00:01<00:05,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58230_27743_0.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|‚ñà‚ñà‚ñà‚ñè      | 8/25 [00:02<00:05,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58250_27761_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|‚ñà‚ñà‚ñà‚ñå      | 9/25 [00:02<00:05,  3.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58301_27800_0.jpeg\n",
      "dataset/mtcnn_faces/testingset\\Adrienne_Frantz\\Adrienne_Frantz_58327_27819_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 11/25 [00:03<00:04,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_78817_35710_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 12/25 [00:03<00:03,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_78942_35766_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 13/25 [00:03<00:03,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_78981_35777_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 14/25 [00:04<00:03,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_79048_35798_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 15/25 [00:04<00:02,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Aisha_Hinds\\Aisha_Hinds_79128_35809_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 16/25 [00:04<00:02,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_1833_992_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 17/25 [00:05<00:02,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_1867_1018_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 18/25 [00:05<00:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_1973_1077_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 19/25 [00:05<00:02,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_1976_1078_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 20/25 [00:06<00:01,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Al_Pacino\\Al_Pacino_2008_1096_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 21/25 [00:06<00:01,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2173_1188_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 22/25 [00:06<00:01,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2209_1218_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 23/25 [00:07<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2225_1229_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 24/25 [00:07<00:00,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2342_1315_0.jpeg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25/25 [00:07<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/mtcnn_faces/testingset\\Alan_Alda\\Alan_Alda_2408_1362_0.jpeg\n",
      "Face detection and cropping completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dirpaths=['dataset/stagging/sampleset','dataset/stagging/testingset']\n",
    "\n",
    "for dirpath in dirpaths:\n",
    "    processed_mtcnn(detector=MTCNN(),dirpath=dirpath,dirdest=dirpath.replace(\"stagging\",\"mtcnn_faces\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Face Verification with DeepFace \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pengujian dilakukan pada google colab (https://colab.research.google.com/drive/1FJffmhncRhJePS87fkacBXv3gSxY8mvz?usp=sharing )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Extract Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_embeddings(dataset_path, output_file, model_name=\"Facenet512\"):\n",
    "    \"\"\"Extracts embeddings and saves them in a pickle file.\"\"\"\n",
    "    embeddings_dict = {}\n",
    "\n",
    "    for person in os.listdir(dataset_path):\n",
    "        person_dir = os.path.join(dataset_path, person)\n",
    "        if not os.path.isdir(person_dir):\n",
    "            continue  # Skip non-directory files\n",
    "\n",
    "        embeddings_dict[person] = {}\n",
    "        for image_name in os.listdir(person_dir):\n",
    "            image_path = os.path.join(person_dir, image_name)\n",
    "            try:\n",
    "                embedding = DeepFace.represent(image_path, model_name=model_name, enforce_detection=False)[0][\"embedding\"]\n",
    "                embeddings_dict[person][image_name] = np.array(embedding)\n",
    "                print(f\"‚úîÔ∏è Extracted embedding for: {image_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error processing {image_path}: {e}\")\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(embeddings_dict, f)\n",
    "    print(f\"‚úÖ Embeddings saved to {output_file}\")\n",
    "\n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(file_path):\n",
    "    \"\"\"Loads the precomputed embeddings from a file.\"\"\"\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        embeddings = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded embeddings from {file_path}\")\n",
    "    return embeddings\n",
    "\n",
    "def verify_faces_with_embeddings(embeddings, person1, img1, person2, img2, threshold=0.4):\n",
    "    \"\"\"Compares precomputed embeddings for face verification.\"\"\"\n",
    "    if person1 not in embeddings or person2 not in embeddings:\n",
    "        print(f\"Error: Person not found in embeddings.\")\n",
    "        return False, None\n",
    "\n",
    "    if img1 not in embeddings[person1] or img2 not in embeddings[person2]:\n",
    "        print(f\"Error: Image not found in embeddings.\")\n",
    "        return False, None\n",
    "\n",
    "    emb1 = embeddings[person1][img1]\n",
    "    emb2 = embeddings[person2][img2]\n",
    "\n",
    "    distance = cosine(emb1, emb2)  # Cosine similarity\n",
    "    verified = distance <= threshold\n",
    "\n",
    "    return verified, distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(train_embeddings, test_embeddings, threshold, model=\"Facenet512\",results_path='/content/drive/MyDrive/dataset_colab/output'):\n",
    "    \"\"\"Evaluates face verification using precomputed embeddings.\"\"\"\n",
    "    results = []\n",
    "    results_dir = f\"{results_path}/results_{threshold}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    for test_person, test_images in test_embeddings.items():\n",
    "        print(f\"Processing test person: {test_person}\")\n",
    "\n",
    "        for train_person, train_images in train_embeddings.items():\n",
    "            if test_person == train_person:\n",
    "                for test_img, test_emb in test_images.items():\n",
    "                    for train_img, train_emb in train_images.items():\n",
    "                        distance = cosine(test_emb, train_emb)\n",
    "                        verified = distance <= threshold\n",
    "\n",
    "                        results.append({\n",
    "                            'train': train_img,\n",
    "                            'test': test_img,\n",
    "                            'verified': verified,\n",
    "                            'y_true': 1,  # Since it's the same person\n",
    "                            'y_pred': 1 if verified else 0,\n",
    "                            'distance': distance,\n",
    "                            'model': model\n",
    "                        })\n",
    "\n",
    "        # Save per-person results\n",
    "        df_person = pd.DataFrame(results)\n",
    "        df_person.to_csv(os.path.join(results_dir, f\"results_{test_person}_{threshold}_{model}.csv\"), index=False)\n",
    "\n",
    "    # Save overall results\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results.to_csv(os.path.join(results_dir, f\"results_{threshold}_{model}.csv\"), index=False)\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=pathd+'/sampleset'\n",
    "val_dir=pathd+'/validationset'\n",
    "test_dir=pathd+'/testingset'\n",
    "threshold=0.4\n",
    "model\n",
    "\n",
    "\n",
    "\n",
    "results_df=evaluate_performance(train_dir=train_dir,test_dir=test_dir,threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(results_df, model_name, threshold,results_path='/content/drive/MyDrive/dataset_colab/output'):\n",
    "    \"\"\"Calculates and exports classification metrics.\"\"\"\n",
    "    y_true = results_df['y_true']\n",
    "    y_pred = results_df['y_pred']\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    TP = cm[1, 1]\n",
    "    TN = cm[0, 0]\n",
    "    FP = cm[0, 1]\n",
    "    FN = cm[1, 0]\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'TP': [TP],\n",
    "        'TN': [TN],\n",
    "        'FP': [FP],\n",
    "        'FN': [FN],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1-Score': [f1]\n",
    "    })\n",
    "\n",
    "    eval_dir = f'{results_path}/results_{threshold}/eval'\n",
    "    os.makedirs(eval_dir, exist_ok=True)\n",
    "    metrics_df.to_csv(f'{eval_dir}/evalmetrics_{model_name}_{threshold}.csv', index=False)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_results(dir_path):\n",
    "    \"\"\"Combines results from CSV files within a directory.\"\"\"\n",
    "    all_results = []\n",
    "    for file_name in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, file_name)  # Form the complete file path\n",
    "        if os.path.isfile(file_path) and file_name.endswith(\".csv\"):  # Check if it's a file and a CSV\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                all_results.append(df)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Warning: File not found - {file_path}\")\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"Warning: Empty file - {file_path}\")\n",
    "    combined_df = pd.concat(all_results, ignore_index=True)\n",
    "    return combined_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
